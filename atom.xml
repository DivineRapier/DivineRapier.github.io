<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>お可愛いこと</title>
  
  
  <link href="http://divinerapier.github.io/atom.xml" rel="self"/>
  
  <link href="http://divinerapier.github.io/"/>
  <updated>2020-11-30T06:17:58.252Z</updated>
  <id>http://divinerapier.github.io/</id>
  
  <author>
    <name>A</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>设置容器内的 locale</title>
    <link href="http://divinerapier.github.io/2020/11/30/set-locale-inside-a-container/"/>
    <id>http://divinerapier.github.io/2020/11/30/set-locale-inside-a-container/</id>
    <published>2020-11-30T02:22:26.000Z</published>
    <updated>2020-11-30T06:17:58.252Z</updated>
    
    <content type="html"><![CDATA[<p>解决办法面向 <strong>Ubuntu/Debian</strong> 系列，<strong>CentOS</strong> 系列方法类似。</p><h2 id="在容器内处理"><a href="#在容器内处理" class="headerlink" title="在容器内处理"></a>在容器内处理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">apt update --fix-missing</span><br><span class="line">apt install -y locales</span><br><span class="line">sed -i <span class="string">'/en_US.UTF-8/s/^# //g'</span> /etc/locale.gen</span><br><span class="line">locale-gen</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"export LANG=en_US.UTF-8"</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"export LANGUAGE=en_US.UTF-8"</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"export LC_ALL=en_US.UTF-8"</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936"</span> &gt;&gt; ~/.vimrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"set termencoding=utf-8"</span> &gt;&gt; ~/.vimrc</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"set encoding=utf-8"</span> &gt;&gt; ~/.vimrc</span><br></pre></td></tr></table></figure><h2 id="在-Dockerfile-中处理"><a href="#在-Dockerfile-中处理" class="headerlink" title="在 Dockerfile 中处理"></a>在 Dockerfile 中处理</h2><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> apt update --fix-missing \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apt install -y locales \</span></span><br><span class="line"><span class="bash">    &amp;&amp; sed -i <span class="string">'/en_US.UTF-8/s/^# //g'</span> /etc/locale.gen \</span></span><br><span class="line"><span class="bash">    &amp;&amp; locale-gen</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">"set fileencodings=utf-8,ucs-bom,gb18030,gbk,gb2312,cp936"</span> &gt;&gt; ~/.vimrc \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">echo</span> <span class="string">"set termencoding=utf-8"</span> &gt;&gt; ~/.vimrc \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">echo</span> <span class="string">"set encoding=utf-8"</span> &gt;&gt; ~/.vimrc</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> LANG en_US.UTF-<span class="number">8</span></span><br><span class="line"><span class="keyword">ENV</span> LANGUAGE en_US.UTF-<span class="number">8</span></span><br><span class="line"><span class="keyword">ENV</span> LC_ALL en_US.UTF-<span class="number">8</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;解决办法面向 &lt;strong&gt;Ubuntu/Debian&lt;/strong&gt; 系列，&lt;strong&gt;CentOS&lt;/strong&gt; 系列方法类似。&lt;/p&gt;
&lt;h2 id=&quot;在容器内处理&quot;&gt;&lt;a href=&quot;#在容器内处理&quot; class=&quot;headerlink&quot; title=&quot;</summary>
      
    
    
    
    
    <category term="linux" scheme="http://divinerapier.github.io/tags/linux/"/>
    
    <category term="container" scheme="http://divinerapier.github.io/tags/container/"/>
    
  </entry>
  
  <entry>
    <title>并行程序设计</title>
    <link href="http://divinerapier.github.io/2020/11/21/introduction-to-parallel-programming/"/>
    <id>http://divinerapier.github.io/2020/11/21/introduction-to-parallel-programming/</id>
    <published>2020-11-21T06:24:38.000Z</published>
    <updated>2020-11-23T02:10:49.040Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么需要并行程序"><a href="#为什么需要并行程序" class="headerlink" title="为什么需要并行程序"></a>为什么需要并行程序</h2><p>单核心的性能不满足需求。</p><h2 id="如何设计并行程序"><a href="#如何设计并行程序" class="headerlink" title="如何设计并行程序"></a>如何设计并行程序</h2><p>在软件层面，通常的方案的基本思想是将要完成的任务分配给各个处理核心。有两种广泛采用的方法: <strong>任务并行</strong> 和 <strong>数据并行</strong>。</p><p>以如下问题解释说明:</p><p>试卷共计 5 道题目，有 100 名学生参加考试，5 名教师阅卷。</p><h3 id="任务并行"><a href="#任务并行" class="headerlink" title="任务并行"></a>任务并行</h3><p>将待解决的问题所需要执行的各个任务分配到各个核心上执行。</p><p>对应到上述问题中，可以认为每个阅卷教师就是一个处理核心，批改每一道题是一个任务。则将任务分配到核心的含义是: 每一名教师只需要负责批阅固定的一道题目。</p><h3 id="数据并行"><a href="#数据并行" class="headerlink" title="数据并行"></a>数据并行</h3><p>将待解决问题所需要处理的数据分配给各个处理核心，每个处理核心执行相同的操作。</p><p>对应到上述问题中，可以认为每个阅卷教师就是一个处理核心，将试卷 —— 也就是数据分配给教师，教师负责试卷的整个批阅过程。各个老师是做的工作是相同的。</p><h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>如何衡量并行程序的性能指标。</p><h3 id="加速比和效率"><a href="#加速比和效率" class="headerlink" title="加速比和效率"></a>加速比和效率</h3>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;为什么需要并行程序&quot;&gt;&lt;a href=&quot;#为什么需要并行程序&quot; class=&quot;headerlink&quot; title=&quot;为什么需要并行程序&quot;&gt;&lt;/a&gt;为什么需要并行程序&lt;/h2&gt;&lt;p&gt;单核心的性能不满足需求。&lt;/p&gt;
&lt;h2 id=&quot;如何设计并行程序&quot;&gt;&lt;a href</summary>
      
    
    
    
    
    <category term="parallel programming" scheme="http://divinerapier.github.io/tags/parallel-programming/"/>
    
  </entry>
  
  <entry>
    <title>测试节点之间的网络带宽</title>
    <link href="http://divinerapier.github.io/2020/11/19/testing-the-bandwidth-between-two-nodes/"/>
    <id>http://divinerapier.github.io/2020/11/19/testing-the-bandwidth-between-two-nodes/</id>
    <published>2020-11-19T05:14:30.000Z</published>
    <updated>2020-11-19T08:05:50.160Z</updated>
    
    <content type="html"><![CDATA[<p>昨天同事找到我，说 <strong>nfs</strong> 太慢了，通过 <strong>iostat</strong> 看只有 <strong>1-2MB/s</strong> 的写入速度。在通过 <strong>fio</strong> 测试磁盘顺序写入速度，得到结果为 <strong>300MB/s</strong> 之后，遂怀疑是网络的问题。</p><h2 id="iperf"><a href="#iperf" class="headerlink" title="iperf"></a>iperf</h2><blockquote><p>iperf is a tool for performing network throughput measurements.  It can test either TCP or UDP throughput.  To perform an iperf test the user must establish both a server (to discard traffic) and a client (to generate traffic).</p></blockquote><p>此处省略安装过程。</p><h3 id="测试网络带宽"><a href="#测试网络带宽" class="headerlink" title="测试网络带宽"></a>测试网络带宽</h3><p><strong>iperf</strong> 通过使用不同的命令行参数，支持分别作为 <strong>服务端</strong> 或 <strong>客户端</strong>。</p><h4 id="启动服务端"><a href="#启动服务端" class="headerlink" title="启动服务端"></a>启动服务端</h4><p>监听默认端口 <strong>5001</strong>，启动服务端:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf -s</span><br></pre></td></tr></table></figure><p>或者，监听指定端口，启动服务端:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf -s -p &lt;port&gt;</span><br></pre></td></tr></table></figure><h4 id="启动客户端"><a href="#启动客户端" class="headerlink" title="启动客户端"></a>启动客户端</h4><p>连接默认端口 <strong>5001</strong>，启动客户端:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf -c &lt;server-host&gt;</span><br></pre></td></tr></table></figure><p>或者，连接指定端口，启动客户端:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf -c &lt;server-host&gt; -p &lt;port&gt;</span><br></pre></td></tr></table></figure><p>同时，<strong>iperf</strong> 也支持多线程的客户端:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iperf -c &lt;server-host&gt; -p &lt;port&gt; -P &lt;threadiness&gt;</span><br></pre></td></tr></table></figure><h4 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h4><p>单线程客户端的测试结果:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">------------------------------------------------------------</span><br><span class="line">Client connecting to 10.33.28.26, TCP port 9999</span><br><span class="line">TCP window size:  170 KByte (default)</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">[  3] <span class="built_in">local</span> 172.29.60.164 port 37290 connected with 10.33.28.26 port 9999</span><br><span class="line">[ ID] Interval       Transfer     Bandwidth</span><br><span class="line">[  3]  0.0-10.6 sec  24.0 MBytes  19.0 Mbits/sec</span><br></pre></td></tr></table></figure><p>多线程客户端的测试结果，两个节点都有 <strong>16</strong> 个 <strong>CPU</strong> 核心:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">------------------------------------------------------------</span><br><span class="line">Client connecting to 10.33.28.26, TCP port 9999</span><br><span class="line">TCP window size: 85.0 KByte (default)</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">[ 18] <span class="built_in">local</span> 172.29.60.164 port 37392 connected with 10.33.28.26 port 9999</span><br><span class="line">[ 17] <span class="built_in">local</span> 172.29.60.164 port 37390 connected with 10.33.28.26 port 9999</span><br><span class="line">[  4] <span class="built_in">local</span> 172.29.60.164 port 37364 connected with 10.33.28.26 port 9999</span><br><span class="line">[ 11] <span class="built_in">local</span> 172.29.60.164 port 37378 connected with 10.33.28.26 port 9999</span><br><span class="line">[  9] <span class="built_in">local</span> 172.29.60.164 port 37374 connected with 10.33.28.26 port 9999</span><br><span class="line">[  8] <span class="built_in">local</span> 172.29.60.164 port 37372 connected with 10.33.28.26 port 9999</span><br><span class="line">[ 10] <span class="built_in">local</span> 172.29.60.164 port 37376 connected with 10.33.28.26 port 9999</span><br><span class="line">[  6] <span class="built_in">local</span> 172.29.60.164 port 37366 connected with 10.33.28.26 port 9999</span><br><span class="line">[ 13] <span class="built_in">local</span> 172.29.60.164 port 37382 connected with 10.33.28.26 port 9999</span><br><span class="line">[ 14] <span class="built_in">local</span> 172.29.60.164 port 37384 connected with 10.33.28.26 port 9999</span><br><span class="line">[  3] <span class="built_in">local</span> 172.29.60.164 port 37362 connected with 10.33.28.26 port 9999</span><br><span class="line">[  5] <span class="built_in">local</span> 172.29.60.164 port 37368 connected with 10.33.28.26 port 9999</span><br><span class="line">[  7] <span class="built_in">local</span> 172.29.60.164 port 37370 connected with 10.33.28.26 port 9999</span><br><span class="line">[ 15] <span class="built_in">local</span> 172.29.60.164 port 37386 connected with 10.33.28.26 port 9999</span><br><span class="line">[ 16] <span class="built_in">local</span> 172.29.60.164 port 37388 connected with 10.33.28.26 port 9999</span><br><span class="line">[ 12] <span class="built_in">local</span> 172.29.60.164 port 37380 connected with 10.33.28.26 port 9999</span><br><span class="line">[ ID] Interval       Transfer     Bandwidth</span><br><span class="line">[  3]  0.0-10.2 sec  2.62 MBytes  2.17 Mbits/sec</span><br><span class="line">[ 13]  0.0-10.2 sec  2.88 MBytes  2.36 Mbits/sec</span><br><span class="line">[ 15]  0.0-10.2 sec  1.88 MBytes  1.54 Mbits/sec</span><br><span class="line">[  7]  0.0-10.9 sec  1.50 MBytes  1.15 Mbits/sec</span><br><span class="line">[  6]  0.0-11.0 sec  1.75 MBytes  1.34 Mbits/sec</span><br><span class="line">[ 17]  0.0-11.2 sec  1.88 MBytes  1.40 Mbits/sec</span><br><span class="line">[  5]  0.0-11.3 sec  1.50 MBytes  1.12 Mbits/sec</span><br><span class="line">[ 10]  0.0-11.6 sec  1.88 MBytes  1.35 Mbits/sec</span><br><span class="line">[  9]  0.0-12.4 sec  1.62 MBytes  1.10 Mbits/sec</span><br><span class="line">[  4]  0.0-13.0 sec  2.88 MBytes  1.85 Mbits/sec</span><br><span class="line">[ 11]  0.0-13.0 sec  4.62 MBytes  2.98 Mbits/sec</span><br><span class="line">[ 14]  0.0-13.1 sec  4.88 MBytes  3.12 Mbits/sec</span><br><span class="line">[  8]  0.0-13.9 sec  2.12 MBytes  1.28 Mbits/sec</span><br><span class="line">[ 16]  0.0-14.1 sec  2.00 MBytes  1.19 Mbits/sec</span><br><span class="line">[ 18]  0.0-14.1 sec  2.12 MBytes  1.26 Mbits/sec</span><br><span class="line">[ 12]  0.0-14.3 sec  1.73 MBytes  1.01 Mbits/sec</span><br><span class="line">[SUM]  0.0-14.3 sec  37.9 MBytes  22.1 Mbits/sec</span><br></pre></td></tr></table></figure><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>瓶颈在网络带宽，悲哀。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;昨天同事找到我，说 &lt;strong&gt;nfs&lt;/strong&gt; 太慢了，通过 &lt;strong&gt;iostat&lt;/strong&gt; 看只有 &lt;strong&gt;1-2MB/s&lt;/strong&gt; 的写入速度。在通过 &lt;strong&gt;fio&lt;/strong&gt; 测试磁盘顺序写入速度，得到结果</summary>
      
    
    
    
    
    <category term="network" scheme="http://divinerapier.github.io/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>Volcano</title>
    <link href="http://divinerapier.github.io/2020/11/16/volcano/"/>
    <id>http://divinerapier.github.io/2020/11/16/volcano/</id>
    <published>2020-11-16T06:43:43.000Z</published>
    <updated>2020-11-18T03:31:38.796Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><p>从 <a href="https://github.com/volcano-sh/volcano/releases" target="_blank" rel="noopener">volocano release</a> 下载 <strong>Volcano</strong>，通过 <strong>yaml</strong> 文件创建 <strong>Deployment</strong> 等。</p><p>以当前版本 <strong>v1.1.0</strong> 为例:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://github.com/volcano-sh/volcano/releases/download/v1.1.0/volcano-v1.1.0-linux-gnu.tar.gz</span><br><span class="line"></span><br><span class="line">$ tar xzf volcano-v1.1.0-linux-gnu.tar.gz</span><br><span class="line"></span><br><span class="line">$ kubectl apply -f ./volcano-v1.1.0.yaml</span><br><span class="line">namespace/volcano-system created</span><br><span class="line">namespace/volcano-monitoring created</span><br><span class="line">configmap/volcano-scheduler-configmap created</span><br><span class="line">serviceaccount/volcano-scheduler created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/volcano-scheduler created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/volcano-scheduler-role created</span><br><span class="line">deployment.apps/volcano-scheduler created</span><br><span class="line">service/volcano-scheduler-service created</span><br><span class="line">serviceaccount/volcano-admission created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/volcano-admission created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/volcano-admission-role created</span><br><span class="line">deployment.apps/volcano-admission created</span><br><span class="line">service/volcano-admission-service created</span><br><span class="line">job.batch/volcano-admission-init created</span><br><span class="line">serviceaccount/volcano-controllers created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/volcano-controllers created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/volcano-controllers-role created</span><br><span class="line">deployment.apps/volcano-controllers created</span><br><span class="line">Warning: apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated <span class="keyword">in</span> v1.16+, unavailable <span class="keyword">in</span> v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/jobs.batch.volcano.sh created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/commands.bus.volcano.sh created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/podgroups.scheduling.volcano.sh created</span><br><span class="line">customresourcedefinition.apiextensions.k8s.io/queues.scheduling.volcano.sh created</span><br></pre></td></tr></table></figure><p>验证 <strong>Volcano</strong> 组件运行状态:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get all -n volcano-system</span><br><span class="line">NAME                                     READY   STATUS      RESTARTS   AGE</span><br><span class="line">pod/volcano-admission-7cfdf5b8d-cd2mk    1/1     Running     0          6m27s</span><br><span class="line">pod/volcano-admission-init-rmd7w         0/1     Completed   0          6m27s</span><br><span class="line">pod/volcano-controllers-c4c5f48b-dtx4w   1/1     Running     0          6m27s</span><br><span class="line">pod/volcano-scheduler-54f77d6788-d6t9j   1/1     Running     0          6m27s</span><br><span class="line"></span><br><span class="line">NAME                                TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">service/volcano-admission-service   ClusterIP   10.5.51.59    &lt;none&gt;        443/TCP    6m27s</span><br><span class="line">service/volcano-scheduler-service   ClusterIP   10.5.128.19   &lt;none&gt;        8080/TCP   6m27s</span><br><span class="line"></span><br><span class="line">NAME                                  READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/volcano-admission     1/1     1            1           6m27s</span><br><span class="line">deployment.apps/volcano-controllers   1/1     1            1           6m27s</span><br><span class="line">deployment.apps/volcano-scheduler     1/1     1            1           6m27s</span><br><span class="line"></span><br><span class="line">NAME                                           DESIRED   CURRENT   READY   AGE</span><br><span class="line">replicaset.apps/volcano-admission-7cfdf5b8d    1         1         1       6m27s</span><br><span class="line">replicaset.apps/volcano-controllers-c4c5f48b   1         1         1       6m27s</span><br><span class="line">replicaset.apps/volcano-scheduler-54f77d6788   1         1         1       6m27s</span><br><span class="line"></span><br><span class="line">NAME                               COMPLETIONS   DURATION   AGE</span><br><span class="line">job.batch/volcano-admission-init   1/1           4m24s      6m27s</span><br></pre></td></tr></table></figure><h2 id="创建任务"><a href="#创建任务" class="headerlink" title="创建任务"></a>创建任务</h2><h3 id="CPU-任务"><a href="#CPU-任务" class="headerlink" title="CPU 任务"></a>CPU 任务</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeflow.org/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">MPIJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">openmpi-helloworld-job</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">volcano</span></span><br><span class="line">  <span class="attr">slotsPerWorker:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">cleanPodPolicy:</span> <span class="string">Running</span></span><br><span class="line">  <span class="attr">mpiReplicaSpecs:</span></span><br><span class="line">    <span class="attr">Launcher:</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">         <span class="attr">spec:</span></span><br><span class="line">           <span class="attr">containers:</span></span><br><span class="line">           <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">divinerapier/openmpi-helloworld:0.0.1</span></span><br><span class="line">             <span class="attr">name:</span> <span class="string">openmpi-helloworld-job</span></span><br><span class="line">             <span class="attr">command:</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">mpirun</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">--allow-run-as-root</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-np</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">"2"</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">/helloworld/mpi_hello_world</span></span><br><span class="line">             <span class="attr">resources:</span></span><br><span class="line">               <span class="attr">request:</span></span><br><span class="line">                 <span class="attr">cpu:</span> <span class="number">0.1</span></span><br><span class="line">               <span class="attr">limits:</span></span><br><span class="line">                 <span class="attr">cpu:</span> <span class="number">0.1</span></span><br><span class="line">    <span class="attr">Worker:</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">divinerapier/openmpi-helloworld:0.0.1</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">openmpi-helloworld-job</span></span><br><span class="line">            <span class="attr">resources:</span></span><br><span class="line">              <span class="attr">request:</span></span><br><span class="line">                <span class="attr">cpu:</span> <span class="number">0.1</span></span><br><span class="line">              <span class="attr">limits:</span></span><br><span class="line">                <span class="attr">cpu:</span> <span class="number">0.1</span></span><br></pre></td></tr></table></figure><h3 id="GPU-任务"><a href="#GPU-任务" class="headerlink" title="GPU 任务"></a>GPU 任务</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeflow.org/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">MPIJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">tensorflow-benchmarks</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">schedulerName:</span> <span class="string">volcano</span></span><br><span class="line">  <span class="attr">slotsPerWorker:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">cleanPodPolicy:</span> <span class="string">Running</span></span><br><span class="line">  <span class="attr">mpiReplicaSpecs:</span></span><br><span class="line">    <span class="attr">Launcher:</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">         <span class="attr">spec:</span></span><br><span class="line">           <span class="attr">containers:</span></span><br><span class="line">           <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">mpioperator/tensorflow-benchmarks:latest</span></span><br><span class="line">             <span class="attr">name:</span> <span class="string">tensorflow-benchmarks</span></span><br><span class="line">             <span class="attr">command:</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">mpirun</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">--allow-run-as-root</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-np</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">"2"</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-bind-to</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">none</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-map-by</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">slot</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-x</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">NCCL_DEBUG=INFO</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-x</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">LD_LIBRARY_PATH</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-x</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">PATH</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-mca</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">pml</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">ob1</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-mca</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">btl</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">^openib</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">python</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">--model=resnet101</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">--batch_size=64</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">--variable_update=horovod</span></span><br><span class="line">             <span class="attr">resources:</span></span><br><span class="line">               <span class="attr">limits:</span></span><br><span class="line">                 <span class="attr">nvidia.com/gpu:</span> <span class="number">1</span></span><br><span class="line">    <span class="attr">Worker:</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">mpioperator/tensorflow-benchmarks:latest</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">tensorflow-benchmarks</span></span><br><span class="line">            <span class="attr">resources:</span></span><br><span class="line">              <span class="attr">limits:</span></span><br><span class="line">                <span class="attr">nvidia.com/gpu:</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p><strong>volcano-scheduler</strong> 在调度任务时，当任务使用的资源太少时会被跳过，具体逻辑为:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">    minMilliCPU <span class="keyword">float64</span> = <span class="number">10</span></span><br><span class="line">    minMilliScalarResources <span class="keyword">float64</span> = <span class="number">10</span></span><br><span class="line">    minMemory <span class="keyword">float64</span> = <span class="number">1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alloc *Action)</span> <span class="title">Execute</span><span class="params">(ssn *framework.Session)</span></span> &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">if</span> _, found = pendingTasks[job.UID]; !found &#123;</span><br><span class="line">        tasks := util.NewPriorityQueue(ssn.TaskOrderFn)</span><br><span class="line">        <span class="keyword">for</span> _, task := <span class="keyword">range</span> job.TaskStatusIndex[api.Pending] &#123;</span><br><span class="line">            <span class="comment">// Skip BestEffort task in 'allocate' action.</span></span><br><span class="line">            <span class="keyword">if</span> task.Resreq.IsEmpty() &#123;</span><br><span class="line">                klog.V(<span class="number">4</span>).Infof(<span class="string">"Task &lt;%v/%v&gt; is BestEffort task, skip it."</span>,</span><br><span class="line">                task.Namespace, task.Name)</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            tasks.Push(task)</span><br><span class="line">        &#125;</span><br><span class="line">        pendingTasks[job.UID] = tasks</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// IsEmpty returns bool after checking any of resource is less than min possible value</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(r *Resource)</span> <span class="title">IsEmpty</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> r.MilliCPU &gt;= minMilliCPU || r.Memory &gt;= minMemory &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _, rQuant := <span class="keyword">range</span> r.ScalarResources &#123;</span><br><span class="line">        <span class="keyword">if</span> rQuant &gt;= minMilliScalarResources &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以，在使用 <strong>volcano</strong> 作为调度器时，必须要对 <strong>Pod</strong> 使用的资源做出限制。对于使用 <strong>volcano</strong> 调度 <strong>MPIJob</strong> 时，无论是 <strong>Launcher</strong> 还是 <strong>Worker</strong> 都需要显示声明需要的资源。</p><p>更具体地，<strong>volcano</strong> 会将资源分为两个大类:</p><ul><li><strong>CPU</strong> 与 <strong>Memory</strong></li><li>其他资源</li></ul><p>要求上述两类资源，至少有一类使用的资源满足最低要求即可。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Installation&quot;&gt;&lt;a href=&quot;#Installation&quot; class=&quot;headerlink&quot; title=&quot;Installation&quot;&gt;&lt;/a&gt;Installation&lt;/h2&gt;&lt;p&gt;从 &lt;a href=&quot;https://github.com/</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://divinerapier.github.io/tags/kubernetes/"/>
    
    <category term="scheduler" scheme="http://divinerapier.github.io/tags/scheduler/"/>
    
  </entry>
  
  <entry>
    <title>调度与驱逐 —— 将 Pod 分配到节点上</title>
    <link href="http://divinerapier.github.io/2020/11/15/scheduling-and-eviction-assigning-pods-to-nodes/"/>
    <id>http://divinerapier.github.io/2020/11/15/scheduling-and-eviction-assigning-pods-to-nodes/</id>
    <published>2020-11-15T10:47:40.000Z</published>
    <updated>2020-11-15T13:38:36.880Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes 允许用户强制 Pod 只能在特定的 Node(s) 上，或者建议优先在特定的 Node(s) 上运行。常规方法是使用 <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/" target="_blank" rel="noopener">Labels and Selectors</a> 来选择。该约束为可选项，默认情况下调度器将自动进行合理的调度，比如，将 pod 分散到节点上，而非在可用资源不足的节点上。但在某些情况下，用户期望对调度 Pod 的 Node(s) 有更多控制，例如，确保 pod 最终落在有 SSD 的机器上，或者将若干有大量通信的服务的 pod 放置在同一个可用区。</p><h2 id="nodeSelector"><a href="#nodeSelector" class="headerlink" title="nodeSelector"></a>nodeSelector</h2><p><strong>nodeSelector</strong> 是最简单推荐形式的节点选择约束。nodeSelector 是 PodSpec 的一个字段，其包含键值对映射。为了使 pod 可以在某个节点上运行，约束键值对构成的集合必须是节点标签集合的子集。</p><h3 id="Get-nodes"><a href="#Get-nodes" class="headerlink" title="Get nodes"></a>Get nodes</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><h3 id="Get-the-names-of-cluster’s-nodes"><a href="#Get-the-names-of-cluster’s-nodes" class="headerlink" title="Get the names of cluster’s nodes"></a>Get the names of cluster’s nodes</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br></pre></td></tr></table></figure><h3 id="Attach-label-to-the-node"><a href="#Attach-label-to-the-node" class="headerlink" title="Attach label to the node"></a>Attach label to the node</h3><p>规则为:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;</span><br></pre></td></tr></table></figure><p>例如，节点 ‘kubernetes-foo-node-1.c.a-robinson.internal’，标签 ‘disktype=ssd’，则可以执行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label nodes kubernetes-foo-node-1.c.a-robinson.internal disktype=ssd</span><br></pre></td></tr></table></figure><p>通过命令验证:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes --show-labels</span><br></pre></td></tr></table></figure><p>或者:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe node &lt;node-name&gt;</span><br></pre></td></tr></table></figure><h3 id="Add-a-nodeSelector-field-to-your-pod-configuration"><a href="#Add-a-nodeSelector-field-to-your-pod-configuration" class="headerlink" title="Add a nodeSelector field to your pod configuration"></a>Add a nodeSelector field to your pod configuration</h3><p>如下为原始 Pod 配置文件:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">env:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br></pre></td></tr></table></figure><p>在此基础上，添加 nodeSelector:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">env:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">  <span class="attr">nodeSelector:</span></span><br><span class="line">    <span class="attr">disktype:</span> <span class="string">ssd</span></span><br></pre></td></tr></table></figure><p>而改文件可以在 <a href="https://k8s.io/examples/pods/pod-nginx.yaml" target="_blank" rel="noopener">https://k8s.io/examples/pods/pod-nginx.yaml</a> 得到。因此，使用如下命令创建 Pod:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://k8s.io/examples/pods/pod-nginx.yaml</span><br></pre></td></tr></table></figure><p>之后，查看 Pod 所在的 Node 并验证约束是否有效:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -o wide</span><br><span class="line"></span><br><span class="line">kubectl describe node &lt;node-name&gt;</span><br></pre></td></tr></table></figure><h3 id="Affinity-and-anti-affinity"><a href="#Affinity-and-anti-affinity" class="headerlink" title="Affinity and anti-affinity"></a>Affinity and anti-affinity</h3><p>Affinity and anti-affinity (亲和与反亲和) 是 nodeSelector 提供的一种非常简单的将 pod 约束到具有特定标签的节点上的方法，极大地扩展了用户可以表达约束的类型。关键增强表现为:</p><ol><li>语言更具表现力，不只是 “完全匹配的 AND” 语义</li><li>规则可以是一种建议性的，而非硬性要求，即使调度器无法找到满足要求的 Node，依旧会调度该 pod</li><li>除了可以使用 Node 本身的标签作为约束之外，还可以使用运行在 Node 上的 pod 的标签作为约束，表明可以或者不可以与哪些 pod 运行在同一 Node 上。</li></ol><p>Affinity 功能包含两种类型的 affinity: <strong>node affinity</strong> 与 <strong>inter-pod affinity/anti-affinity</strong>。<strong>node affinity</strong> 类似于 <strong>nodeSelector</strong>，对应上述 <strong>1,2</strong> 两点优势。而 <strong>inter-pod affinity/anti-affinity</strong> 具有上述 <strong>1,2,3</strong> 三点优势。</p><h4 id="Node-affinity"><a href="#Node-affinity" class="headerlink" title="Node affinity"></a>Node affinity</h4><p><strong>Node affinity</strong> 概念上类似于 <strong>nodeSelector</strong>，可以根据节点上的标签来约束 pod 可以调度到哪些节点。</p><p>目前有两种类型的 Node affinity，分别为 <strong>requiredDuringSchedulingIgnoredDuringExecution</strong> 和 <strong>preferredDuringSchedulingIgnoredDuringExecution</strong>。</p><p><strong>requiredDuringSchedulingIgnoredDuringExecution</strong> 指定了将 pod 调度到一个节点上必须满足的规则，原则上等同于 nodeSelector，但语法更具有表现力。</p><p><strong>preferredDuringSchedulingIgnoredDuringExecution</strong> 指定调度器将尝试执行但不能保证的偏好。</p><p>名称中 <strong>IgnoredDuringExecution</strong> 类似于 <strong>nodeSelector</strong> 的用法，表明如果节点的标签在 Pod 运行时发生变更，从而不再满足 pod 上的 affinity 规则时，pod 将仍然继续运行在原节点上。<strong>requiredDuringSchedulingRequiredDuringExecution</strong> 还只存在于计划中。</p><p>因此，在下面的示例中:</p><ul><li><strong>requiredDuringSchedulingIgnoredDuringExecution</strong> 的含义为: <strong>必须将 pod 运行在具有 kubernetes.io/e2e-az-name=e2e-az1 或 kubernetes.io/e2e-az-name=e2e-az2 标签的 Node 上</strong></li><li><strong>preferredDuringSchedulingIgnoredDuringExecution</strong> 的含义为: <strong>尝试将 pod 运行具有 another-node-label-key=another-node-label-value 标签的 Node 上，如果这不可能的话，则允许 pod 在其他地方运行</strong></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">        <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/e2e-az-name</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">e2e-az1</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">e2e-az2</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">preference:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">another-node-label-key</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">another-node-label-value</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">k8s.gcr.io/pause:2.0</span></span><br></pre></td></tr></table></figure><p>Node affinity 语法支持的操作符: In，NotIn，Exists，DoesNotExist，Gt，Lt。使用 NotIn 和 DoesNotExist 来实现 <strong>node anti-affinity</strong> 行为，或者使用 <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/" target="_blank" rel="noopener">node taints(节点污点将)</a> pod 从特定节点中驱逐。</p><p>如果同时指定了 <strong>nodeSelector</strong> 和 <strong>nodeAffinity</strong>，则要求两者必须同时满足，才能将 pod 调度到候选 Node 上。</p><p>如果指定了多个与 <strong>nodeAffinity</strong> 类型关联的 <strong>nodeSelectorTerms</strong>，则 Node 只需要满足其中任何一个 nodeSelectorTerms 即可将 pod 调度到 Node 上。</p><p>如果指定了多个与 <strong>nodeSelectorTerms</strong> 关联的 <strong>matchExpressions</strong>，则当且仅当所有 <strong>matchExpressions</strong> 得到满足时才将 pod 调度到该 Node 上。</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/" target="_blank" rel="noopener">Assigning Pods to Nodes</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Kubernetes 允许用户强制 Pod 只能在特定的 Node(s) 上，或者建议优先在特定的 Node(s) 上运行。常规方法是使用 &lt;a href=&quot;https://kubernetes.io/docs/concepts/overview/working-with-</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://divinerapier.github.io/tags/kubernetes/"/>
    
    <category term="scheduling" scheme="http://divinerapier.github.io/tags/scheduling/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Device Plugin</title>
    <link href="http://divinerapier.github.io/2020/11/15/kubernetes-device-plugin/"/>
    <id>http://divinerapier.github.io/2020/11/15/kubernetes-device-plugin/</id>
    <published>2020-11-15T09:20:26.000Z</published>
    <updated>2020-11-15T10:27:25.570Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes 提供 <a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/device-plugin.md" target="_blank" rel="noopener">device plugin framework</a>，允许用户将系统硬件资源发布到 Kubelet。</p><p>Device Plugin 由设备供应商实现，由用户或手动部署或作为 DaemonSet 来部署，而无需定制 Kubernetes 本身的代码。目标设备可以是 GPU、高性能 NIC、FPGA、InfiniBand 适配器以及其他类似的、可能需要特定于供应商的初始化和设置的计算资源。</p><h2 id="注册-Device-Plugin"><a href="#注册-Device-Plugin" class="headerlink" title="注册 Device Plugin"></a>注册 Device Plugin</h2><p>kubelet 提供了一个 Registration 的 gRPC 服务:</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">service</span> <span class="title">Registration</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> Register(RegisterRequest) <span class="keyword">returns</span> (Empty) &#123;&#125;</span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><p><strong>Device Plugin</strong> 可以通过此 gRPC 服务在 kubelet 进行注册。在注册时，<strong>Device Plugin</strong> 需要提供如下内容:</p><ul><li>Device Plugin 的 Unix 套接字。</li><li>Device Plugin 的 API 版本。</li><li>ResourceName。遵循 <a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#extended-resources" target="_blank" rel="noopener">扩展资源命名方案</a>，形如 vendor-domain/resourcetype: 比如 NVIDIA GPU 就被公布为 nvidia.com/gpu。</li></ul><p>在成功注册后，<strong>Device Plugin</strong> 会向 kubelet 发送他所管理的设备列表，之后 kubelet 负责将这些资源发布到 API Server，作为 kubelet 节点状态更新的一部分。</p><p>比如，<strong>Device Plugin</strong> 在 kubelet 中注册了 <strong>hardware-vendor.example/foo</strong> 并报告了节点上的两个运行状况良好的设备后，节点状态将更新以通告该节点已安装2个 Foo 设备并且是可用的。</p><p>然后，用户就可以在 Container 规范中请求这类设备，但是有以下的限制:</p><ul><li>扩展资源仅可作为整数资源使用，且不能被过量使用</li><li>设备不能在容器之间共享</li></ul><p>假设 Kubernetes 集群正在运行一个 <strong>Device Plugin</strong>，ResourceName 为 <strong>hardware-vendor.example/foo</strong>。下面就是一个 Pod 示例，请求此资源以运行某演示负载：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">demo-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">demo-container-1</span></span><br><span class="line">      <span class="attr">image:</span> <span class="string">k8s.gcr.io/pause:2.0</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">limits:</span></span><br><span class="line">          <span class="attr">hardware-vendor.example/foo:</span> <span class="number">2</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># pod 需要两个 hardware-vendor.example/foo 设备</span></span><br><span class="line"><span class="comment"># 而且只能够调度到满足需求的 node 上</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># 如果该节点中有2个以上的设备可用，剩余的设备可供其他 pod 使用</span></span><br></pre></td></tr></table></figure><h2 id="实现-Device-Plugin"><a href="#实现-Device-Plugin" class="headerlink" title="实现 Device Plugin"></a>实现 Device Plugin</h2><p>Device Plugin 的常规工作流程包括以下几个步骤：</p><ul><li><p>初始化。在这个阶段，Device Plugin 将执行供应商特定的初始化和设置，以确保设备处于就绪状态。</p></li><li><p>使用主机路径 /var/lib/kubelet/device-plugins/ 下的 Unix socket 启动一个 gRPC 服务，该服务实现以下接口：</p>  <figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">service</span> <span class="title">DevicePlugin</span> </span>&#123;</span><br><span class="line">    <span class="comment">// GetDevicePluginOptions returns options to be communicated with Device Manager.</span></span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> GetDevicePluginOptions(Empty) <span class="keyword">returns</span> (DevicePluginOptions) &#123;&#125;</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    // ListAndWatch <span class="keyword">returns</span> a stream of List of Devices</span></span><br><span class="line"><span class="function">    // Whenever a Device state change or a Device disappears, ListAndWatch</span></span><br><span class="line"><span class="function">    // <span class="keyword">returns</span> the new list</span></span><br><span class="line"><span class="function">    <span class="keyword">rpc</span> ListAndWatch(Empty) <span class="keyword">returns</span> (stream ListAndWatchResponse) &#123;&#125;</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    // Allocate is called during container creation so that the Device</span></span><br><span class="line"><span class="function">    // Plugin can run device specific operations and instruct Kubelet</span></span><br><span class="line"><span class="function">    // of the steps to make the Device available in the container</span></span><br><span class="line"><span class="function">    <span class="keyword">rpc</span> Allocate(AllocateRequest) <span class="keyword">returns</span> (AllocateResponse) &#123;&#125;</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    // GetPreferredAllocation <span class="keyword">returns</span> a preferred set of devices to allocate</span></span><br><span class="line"><span class="function">    // from a list of available ones. The resulting preferred allocation is not</span></span><br><span class="line"><span class="function">    // guaranteed to be the allocation ultimately performed by the</span></span><br><span class="line"><span class="function">    // devicemanager. It is only designed to help the devicemanager make a more</span></span><br><span class="line"><span class="function">    // informed allocation decision when possible.</span></span><br><span class="line"><span class="function">    <span class="keyword">rpc</span> GetPreferredAllocation(PreferredAllocationRequest) <span class="keyword">returns</span> (PreferredAllocationResponse) &#123;&#125;</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    // PreStartContainer is called, if indicated by Device Plugin during registeration phase,</span></span><br><span class="line"><span class="function">    // before each container start. Device plugin can run device specific operations</span></span><br><span class="line"><span class="function">    // such as resetting the device before making devices available to the container.</span></span><br><span class="line"><span class="function">    <span class="keyword">rpc</span> PreStartContainer(PreStartContainerRequest) <span class="keyword">returns</span> (PreStartContainerResponse) &#123;&#125;</span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>通过 Unix socket 在主机路径 /var/lib/kubelet/device-plugins/kubelet.sock 处向 kubelet 注册自身。</p></li><li><p>成功注册自身后，Device Plugin 将以服务模式运行，之后，它将持续监控设备运行状况，并在设备状态发生任何变化时报告 kubelet。它还负责响应 Allocate gRPC 请求。 在 Allocate 期间，Device Plugin 可能还会做一些设备特定的准备；例如清理 GPU 或初始化 QRNG。如果操作成功，则 Device Plugin 将返回 AllocateResponse，其中包含用于访问被分配的设备容器运行时的配置。 kubelet 将此信息传递到容器运行时。</p></li></ul><h3 id="处理-kubelet-重启"><a href="#处理-kubelet-重启" class="headerlink" title="处理 kubelet 重启"></a>处理 kubelet 重启</h3><p>Device Plugin 应能监测到 kubelet 重启，并且向新的 kubelet 实例来重新注册自己。在当前实现中，当 kubelet 重启的时候，新的 kubelet 实例会删除 /var/lib/kubelet/device-plugins 下所有已经存在的 Unix sockets。 Device Plugin 需要能够监控到它的 Unix socket 被删除，并且当发生此类事件时重新注册自己。</p><h2 id="部署-Device-Plugin"><a href="#部署-Device-Plugin" class="headerlink" title="部署 Device Plugin"></a>部署 Device Plugin</h2><p>用户可以将 Device Plugin 作为节点操作系统的软件包来部署、作为 DaemonSet 来部署或者手动部署。</p><p>规范目录 /var/lib/kubelet/device-plugins 是需要特权访问的，所以 Device Plugin 必须要在被授权的安全的上下文中运行。如果将 Device Plugin 部署为 DaemonSet，/var/lib/kubelet/device-plugins 目录必须要在 DevicePlugin 的 PodSpec 中声明作为 Volume 被 mount 到 Device Plugin 中。</p><p>若选择 DaemonSet 方法，用户可以通过 Kubernetes 进行以下操作: 将 Device Plugin 的 Pod 放置在节点上，在出现故障后重新启动守护进程 Pod，来进行自动升级。</p><h2 id="API-兼容性"><a href="#API-兼容性" class="headerlink" title="API 兼容性"></a>API 兼容性</h2><p>Kubernetes Device Plugin 还处于 beta 版本。所以在稳定版本出来之前 API 会以不兼容的方式进行更改。作为一个项目，Kubernetes 建议 Device Plugin 开发者:</p><ul><li>注意未来版本的更改</li><li>支持多个版本的 Device Plugin API，以实现向后/向前兼容性。</li></ul><p>如果你启用 DevicePlugins 功能，并在需要升级到 Kubernetes 版本来获得较新的 Device Plugin API 版本的节点上运行 Device Plugin，请在升级这些节点之前先升级 Device Plugin 以支持这两个版本。 采用该方法将确保升级期间设备分配的连续运行。</p><h2 id="监控-Device-Plugin"><a href="#监控-Device-Plugin" class="headerlink" title="监控 Device Plugin"></a>监控 Device Plugin</h2><p>为了监控 Device Plugin 提供的资源，监控代理程序需要能够发现节点上正在使用的设备，并获取元数据来描述哪个指标与容器相关联。 设备监控代理暴露给 <a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a> 的指标应该遵循 <a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/instrumentation.md" target="_blank" rel="noopener">Kubernetes Instrumentation Guidelines</a>，使用 pod、namespace 和 container 标签来标识容器。</p><p>kubelet 提供了 gRPC 服务来使得正在使用中的设备被发现，并且还未这些设备提供了元数据:</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// PodResourcesLister is a service provided by the kubelet that provides information about the</span></span><br><span class="line"><span class="comment">// node resources consumed by pods and containers on the node</span></span><br><span class="line"><span class="class"><span class="keyword">service</span> <span class="title">PodResourcesLister</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">rpc</span> List(ListPodResourcesRequest) <span class="keyword">returns</span> (ListPodResourcesResponse) &#123;&#125;</span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><p>gRPC 服务通过 /var/lib/kubelet/pod-resources/kubelet.sock 的 UNIX 套接字来提供服务。 Device Plugin资源的监控代理程序可以部署为守护进程或者 DaemonSet。 规范的路径 /var/lib/kubelet/pod-resources 需要特权来进入， 所以监控代理程序必须要在获得授权的安全的上下文中运行。 如果设备监控代理以 DaemonSet 形式运行，必须要在插件的 PodSpec 中声明将 /var/lib/kubelet/pod-resources 目录以 卷的形式被挂载到容器中。</p><p>对“PodResources 服务”的支持要求启用 KubeletPodResources 特性门控。 从 Kubernetes 1.15 开始默认启用。</p><h2 id="Device-Plugin-集成-The-Topology-Manager"><a href="#Device-Plugin-集成-The-Topology-Manager" class="headerlink" title="Device Plugin 集成 The Topology Manager"></a>Device Plugin 集成 The Topology Manager</h2><p>The Topology Manager 是 Kubelet 的一个组件，它允许以拓扑对齐方式来调度资源。 为了做到这一点，Device Plugin API 进行了扩展来包括一个 TopologyInfo 结构体。</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">TopologyInfo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">repeated</span> NUMANode nodes = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">message</span> <span class="title">NUMANode</span> </span>&#123;</span><br><span class="line">    <span class="built_in">int64</span> ID = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Device Plugin 希望 The Topology Manager 可以将填充的 TopologyInfo 结构体作为设备注册的一部分以及设备 ID 和设备的运行状况发送回去。然后 The Topology Manager 将使用此信息来咨询拓扑管理器并做出资源分配决策。</p><p>TopologyInfo 支持定义 nodes 字段，允许为 nil（默认）或者是一个 NUMA 节点的列表。 这样就可以使Device Plugin可以跨越 NUMA 节点去发布。</p><p>下面是一个由 Device Plugin 为设备填充 TopologyInfo 结构体的示例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pluginapi.Device&#123;ID: &quot;25102017&quot;, Health: pluginapi.Healthy, Topology:&amp;pluginapi.TopologyInfo&#123;Nodes: []*pluginapi.NUMANode&#123;&amp;pluginapi.NUMANode&#123;ID: 0,&#125;,&#125;&#125;&#125;</span><br></pre></td></tr></table></figure><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/" target="_blank" rel="noopener">Kubernetes Device Plugin</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Kubernetes 提供 &lt;a href=&quot;https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/device-plugi</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Nvidia Docker</title>
    <link href="http://divinerapier.github.io/2020/11/14/nvidia-docker/"/>
    <id>http://divinerapier.github.io/2020/11/14/nvidia-docker/</id>
    <published>2020-11-14T10:21:01.000Z</published>
    <updated>2020-11-14T14:17:09.039Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/nvidia-docker/nvidia-container-toolkit.png" alt="nvidia-container-toolkit.png"></p><p>Nvidia Container Toolkit 包含容器运行时库和一些工具，用于自动配置容器使用 GPU 资源。并且，支持多种不同的容器引擎，如 Docker、LXC、Podman 等。用户根据需要可以自行选择使用哪种引擎。</p><h2 id="The-Architecture-Overview-of-Nvidia-Container-Toolkit"><a href="#The-Architecture-Overview-of-Nvidia-Container-Toolkit" class="headerlink" title="The Architecture Overview of Nvidia Container Toolkit"></a>The Architecture Overview of Nvidia Container Toolkit</h2><p>Nvidia Container Toolkit 的架构允许其支持任何容器运行时。若以 Docker 为例，其由以下组件，以从上到下的层次结构组成:</p><ul><li>nvidia-docker2</li><li>nvidia-container-runtime</li><li>nvidia-container-toolkit</li><li>libnvidia-container</li></ul><p>下图为各个组件的关系:</p><p><img src="/images/nvidia-docker/nvidia-docker-arch.png" alt="nvidia-docker-arch.png"></p><h3 id="Components-and-Packages"><a href="#Components-and-Packages" class="headerlink" title="Components and Packages"></a>Components and Packages</h3><h4 id="libnvidia-container"><a href="#libnvidia-container" class="headerlink" title="libnvidia-container"></a>libnvidia-container</h4><p>提供库与 CLI 程序，实现自动化配置 GNU/Linux 容器使用 NVIDIA GPU 资源，其实现依赖于内核基础功能，且在设计上与容器运行时解耦。</p><p>libnvidia-container 提供了一个定义良好的 API 和一个封装好的 CLI 程序(nvidia-container-cli)，任何容器运行时都可以调用它来支持 NVIDIA GPU。</p><h4 id="nvidia-container-toolkit"><a href="#nvidia-container-toolkit" class="headerlink" title="nvidia-container-toolkit"></a>nvidia-container-toolkit</h4><p>实现了 runC prestart hook 需要的接口的脚本。该脚本在容器被创建之后，启动之前被 runC 调用，且被赋予访问与容器相关联的 config.json 的权限。脚本根据 config.json 中的信息作为合适的命令行参数 (an appropriate set of flags) 来调用 libnvidia-container CLI。其中，“指定哪些 GPU 设备在容器中使用” 是最重要的参数。</p><p>该组件之前的名字是 nvidia-container-runtime-hook，现在系统上的 nvidia-container-runtime-hook 是 nvidia-container-toolkit 的符号链接。</p><h4 id="nvidia-container-runtime"><a href="#nvidia-container-runtime" class="headerlink" title="nvidia-container-runtime"></a>nvidia-container-runtime</h4><p>曾经，nvidia-container-runtime 以 runC 作为基础，添加了 NVIDIA 特定的代码。2019 年，更改为对宿主机上原生 runC 做简单的封装。nvidia-container-runtime 将 runC spec 作为输入，将 nvidia-container-toolkit 脚本作为 prestart hook 注入到 runC spec 中。然后，将修改后的带有该 hook set 的 runC spec 传递给原生 runC 并调用 runC。需要注意的是，该组件不一定是针对 docker 的(但它是针对runC的)。</p><p>当该 package 完成安装后，Docker 的 daemon.json 文件会被更新为指向这个二进制文件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line"><span class="string">"default-runtime"</span>: <span class="string">"nvidia"</span>,</span><br><span class="line"><span class="string">"runtimes"</span>: &#123;</span><br><span class="line">    <span class="string">"nvidia"</span>: &#123;</span><br><span class="line">        <span class="string">"path"</span>: <span class="string">"/usr/bin/nvidia-container-runtime"</span>,</span><br><span class="line">        <span class="string">"runtimeArgs"</span>: []</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="nvidia-docker2"><a href="#nvidia-docker2" class="headerlink" title="nvidia-docker2"></a>nvidia-docker2</h4><p>这个 package 是架构中唯一的 docker 专用包。它采用与 nvidia-container-runtime 相关的脚本，并将其安装到 docker 的 /etc/docker/daemon.json 文件中。这样，使用者就可以运行 <strong>docker run –runtime=nvidia …</strong> 来自动为容器添加对 GPU 的支持。这个 package 还安装了一个封装了原生 docker CLI 的脚本，名为 nvidia-docker，避免每次都指定 –runtime=nvidia 来调用 docker。它还允许用户在宿主机上设置环境变量 NV_GPU 来指定将哪些 GPU 注入到容器中。</p><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><h3 id="Pre-Requisites"><a href="#Pre-Requisites" class="headerlink" title="Pre-Requisites"></a>Pre-Requisites</h3><ul><li><a href="https://www.nvidia.com/Download/index.aspx?lang=en-us" target="_blank" rel="noopener">NVIDIA Drivers</a></li><li>Platform Requirements:<ol><li>GNU/Linux x86_64 with kernel version &gt; 3.10</li><li>Docker &gt;= 19.03 (recommended, but some distributions may include older versions of Docker. The minimum supported version is 1.12)</li><li>NVIDIA GPU with Architecture &gt; Fermi (or compute capability 2.1)</li><li>NVIDIA drivers ~= 361.93 (untested on older versions)</li></ol></li><li>Docker CE</li></ul><h3 id="Setting-up-NVIDIA-Container-Toolkit"><a href="#Setting-up-NVIDIA-Container-Toolkit" class="headerlink" title="Setting up NVIDIA Container Toolkit"></a>Setting up NVIDIA Container Toolkit</h3><p>安装软件源与 GPG key:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ distribution=$(. /etc/os-release;<span class="built_in">echo</span> <span class="variable">$ID</span><span class="variable">$VERSION_ID</span>) \</span><br><span class="line">   &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \</span><br><span class="line">   &amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br></pre></td></tr></table></figure><p>安装 nvidia-docker2 并重启 Docker Daemon:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get update \</span><br><span class="line">   &amp;&amp; sudo apt-get install -y nvidia-docker2 \</span><br><span class="line">   &amp;&amp; sudo systemctl restart docker</span><br></pre></td></tr></table></figure><p>启动容器测试，如果得到类似如下的输出则安装成功:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |</span><br><span class="line">| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N/A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://docs.nvidia.com/datacenter/cloud-native/index.html" target="_blank" rel="noopener">NVIDIA Cloud Native Technologies</a></li><li><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html" target="_blank" rel="noopener">Container Toolkit Installation Guide</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;img src=&quot;/images/nvidia-docker/nvidia-container-toolkit.png&quot; alt=&quot;nvidia-container-toolkit.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;Nvidia Container Toolkit 包含容器运行时</summary>
      
    
    
    
    
    <category term="gpu" scheme="http://divinerapier.github.io/tags/gpu/"/>
    
    <category term="docker" scheme="http://divinerapier.github.io/tags/docker/"/>
    
    <category term="nvidia" scheme="http://divinerapier.github.io/tags/nvidia/"/>
    
  </entry>
  
  <entry>
    <title>为 Linux 增加新磁盘</title>
    <link href="http://divinerapier.github.io/2020/11/01/adding-a-new-hard-drive-for-linux/"/>
    <id>http://divinerapier.github.io/2020/11/01/adding-a-new-hard-drive-for-linux/</id>
    <published>2020-11-01T12:41:21.000Z</published>
    <updated>2020-11-01T14:22:45.887Z</updated>
    
    <content type="html"><![CDATA[<h2 id="查看设备文件"><a href="#查看设备文件" class="headerlink" title="查看设备文件"></a>查看设备文件</h2><p>将磁盘插入计算机后，在终端中查看:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ lsblk -d -o name,serial</span><br><span class="line"></span><br><span class="line">NAME    SERIAL</span><br><span class="line">nvme0n1 200000000000</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo fdisk -l</span><br><span class="line"></span><br><span class="line">Disk /dev/nvme0n1: 931.53 GiB, 1000204886016 bytes, 1953525168 sectors</span><br><span class="line">Disk model: WDS100T3X0C-00SJG0</span><br><span class="line">Units: sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br></pre></td></tr></table></figure><p>可以确认设备文件为 <code>/dev/nvme0n1</code>。</p><h2 id="创建分区"><a href="#创建分区" class="headerlink" title="创建分区"></a>创建分区</h2><p>创建分区表:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo parted /dev/nvme0n1 mklabel gpt</span><br><span class="line"></span><br><span class="line">Information: You may need to update /etc/fstab.</span><br></pre></td></tr></table></figure><p>创建主分区，并确认对齐:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo parted -s -m /dev/nvme0n1 mkpart primary ext4 1 100%</span><br><span class="line"></span><br><span class="line">$ sudo parted /dev/nvme0n1 align-check opt 1</span><br><span class="line">1 aligned</span><br></pre></td></tr></table></figure><p>查看分区详细信息:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sudo parted /dev/nvme0n1 <span class="built_in">print</span></span><br><span class="line">Model: WDS100T3X0C-00SJG0 (nvme)</span><br><span class="line">Disk /dev/nvme0n1: 1000GB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: gpt</span><br><span class="line">Disk Flags:</span><br><span class="line"></span><br><span class="line">Number  Start   End     Size    File system  Name     Flags</span><br><span class="line"> 1      1049kB  1000GB  1000GB               primary</span><br></pre></td></tr></table></figure><h2 id="使用磁盘"><a href="#使用磁盘" class="headerlink" title="使用磁盘"></a>使用磁盘</h2><p>创建文件系统:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkfs.ext4 /dev/nvme0n1p1</span><br><span class="line"></span><br><span class="line">mke2fs 1.45.5 (07-Jan-2020)</span><br><span class="line">Discarding device blocks: <span class="keyword">done</span></span><br><span class="line">Creating filesystem with 244190208 4k blocks and 61054976 inodes</span><br><span class="line">Filesystem UUID: b5424944-2d8c-4c5f-8bb4-0e538db5592b</span><br><span class="line">Superblock backups stored on blocks:</span><br><span class="line">        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,</span><br><span class="line">        4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968,</span><br><span class="line">        102400000, 214990848</span><br><span class="line"></span><br><span class="line">Allocating group tables: <span class="keyword">done</span></span><br><span class="line">Writing inode tables: <span class="keyword">done</span></span><br><span class="line">Creating journal (262144 blocks): <span class="keyword">done</span></span><br><span class="line">Writing superblocks and filesystem accounting information: <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>挂载磁盘:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkdir -p /nvme</span><br><span class="line"></span><br><span class="line">$ sudo mount /dev/nvme0n1p1 /nvme</span><br><span class="line"></span><br><span class="line">$ df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/nvme0n1p1  916G   77M  870G   1% /nvme</span><br></pre></td></tr></table></figure><h2 id="测试磁盘"><a href="#测试磁盘" class="headerlink" title="测试磁盘"></a>测试磁盘</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /nvme</span><br><span class="line"></span><br><span class="line"><span class="comment"># ioengine: 可以指定为 psync / libaio</span></span><br><span class="line"><span class="comment"># numjobs: 测试线程数，线程之间的测试相互独立，成倍占用 size 指定的大小</span></span><br><span class="line"><span class="comment"># rw: 读写方式</span></span><br><span class="line"><span class="comment">#     read: 顺序读</span></span><br><span class="line"><span class="comment">#     write: 顺序写</span></span><br><span class="line"><span class="comment">#     randread: 随机读</span></span><br><span class="line"><span class="comment">#     randwrite: 随机写</span></span><br><span class="line"><span class="comment"># bs: 每次读写块大小</span></span><br><span class="line">$ sudo fio -direct=1 -iodepth 1 -thread -rw=randread -ioengine=psync -bs=4k -size=100G -numjobs=4 -group_reporting -name=file</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;查看设备文件&quot;&gt;&lt;a href=&quot;#查看设备文件&quot; class=&quot;headerlink&quot; title=&quot;查看设备文件&quot;&gt;&lt;/a&gt;查看设备文件&lt;/h2&gt;&lt;p&gt;将磁盘插入计算机后，在终端中查看:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;</summary>
      
    
    
    
    
    <category term="linux" scheme="http://divinerapier.github.io/tags/linux/"/>
    
    <category term="hard drive" scheme="http://divinerapier.github.io/tags/hard-drive/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes DaemonSet</title>
    <link href="http://divinerapier.github.io/2020/10/28/kubernetes-daemonset/"/>
    <id>http://divinerapier.github.io/2020/10/28/kubernetes-daemonset/</id>
    <published>2020-10-28T06:41:29.000Z</published>
    <updated>2020-10-28T08:13:15.385Z</updated>
    
    <content type="html"><![CDATA[<p><strong>DaemonSet</strong> 确保全部 (或者某些) 节点上运行一个 Pod 的副本。 当有节点加入集群时，也会为他们新增一个 Pod 。当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。</p><p>DaemonSet 的一些典型用法:</p><ul><li>在每个节点上运行集群守护进程<ul><li>比如: 网络插件，存储插件</li></ul></li><li>在每个节点上运行日志收集守护进程</li><li>在每个节点上运行监控守护进程</li></ul><h2 id="创建-DaemonSet"><a href="#创建-DaemonSet" class="headerlink" title="创建 DaemonSet"></a>创建 DaemonSet</h2><p>下面的 <strong>daemonset.yaml</strong> 文件描述了一个运行 <strong>fluentd-elasticsearch</strong> Docker 镜像的 DaemonSet:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kube-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">fluentd-logging</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">tolerations:</span></span><br><span class="line">      <span class="comment"># this toleration is to have the daemonset runnable on master nodes</span></span><br><span class="line">      <span class="comment"># remove it if your masters can't run pods</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line">        <span class="attr">effect:</span> <span class="string">NoSchedule</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fluentd-elasticsearch</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">quay.io/fluentd_elasticsearch/fluentd:v2.5.2</span></span><br><span class="line">        <span class="attr">resources:</span></span><br><span class="line">          <span class="attr">limits:</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">          <span class="attr">requests:</span></span><br><span class="line">            <span class="attr">cpu:</span> <span class="string">100m</span></span><br><span class="line">            <span class="attr">memory:</span> <span class="string">200Mi</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/log</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/var/lib/docker/containers</span></span><br><span class="line">          <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">30</span></span><br><span class="line">      <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlog</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/log</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">varlibdockercontainers</span></span><br><span class="line">        <span class="attr">hostPath:</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">/var/lib/docker/containers</span></span><br></pre></td></tr></table></figure><p>使用 <strong>yaml</strong> 文件创建 <strong>DaemonSet</strong>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://k8s.io/examples/controllers/daemonset.yaml</span><br></pre></td></tr></table></figure><h2 id="如何调度-Daemon-Pods"><a href="#如何调度-Daemon-Pods" class="headerlink" title="如何调度 Daemon Pods"></a>如何调度 Daemon Pods</h2><h3 id="通过默认调度器调度"><a href="#通过默认调度器调度" class="headerlink" title="通过默认调度器调度"></a>通过默认调度器调度</h3><p>DaemonSet 确保所有符合条件的节点都运行该 Pod 的一个副本。 通常，运行 Pod 的节点由 Kubernetes 调度器选择。不过，DaemonSet pods 由 DaemonSet 控制器创建和调度。这就带来了以下问题:</p><ul><li>Pod 行为的不一致性: 正常 Pod 在被创建后等待调度时处于 Pending 状态， DaemonSet Pods 创建后不会处于 Pending 状态下。这使用户感到困惑。</li><li><a href="https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/" target="_blank" rel="noopener">Pod 抢占</a> 由默认调度器处理。启用抢占后，DaemonSet 控制器将在不考虑 Pod 优先级和抢占 的情况下制定调度决策。</li></ul><p><strong>ScheduleDaemonSetPods</strong> 控制 Kubernetes 使用 <strong>默认调度器</strong> 而不是 <strong>DaemonSet 控制器</strong> 来调度 DaemonSets，通过将 <strong>yaml</strong> 配置文件中 <strong>Pod</strong> 部分的 <strong>.spec.nodeName</strong> 替换为 <strong>.spec.affinity.nodeAffinity</strong>。更多内容请点击 <a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity" target="_blank" rel="noopener">Assigning Pods to Nodes: Affinity and anti-affinity</a>。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">affinity:</span></span><br><span class="line">    <span class="attr">nodeAffinity:</span></span><br><span class="line">      <span class="attr">requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">        <span class="attr">nodeSelectorTerms:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">matchExpressions:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">kubernetes.io/e2e-az-name</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">e2e-az1</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">e2e-az2</span></span><br><span class="line">      <span class="attr">preferredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">weight:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">preference:</span></span><br><span class="line">          <span class="attr">matchExpressions:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">key:</span> <span class="string">another-node-label-key</span></span><br><span class="line">            <span class="attr">operator:</span> <span class="string">In</span></span><br><span class="line">            <span class="attr">values:</span></span><br><span class="line">            <span class="bullet">-</span> <span class="string">another-node-label-value</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">with-node-affinity</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">k8s.gcr.io/pause:2.0</span></span><br></pre></td></tr></table></figure><ul><li><strong>requiredDuringSchedulingIgnoredDuringExecution</strong>: 必须将 Pod 部署到满足条件的节点上，否则不断重试</li><li><strong>preferredDuringSchedulingIgnoredDuringExecution</strong>: 优先将 Pod 部署到满足条件的节点上，否则忽略该条件</li></ul><p>此外，系统会自动添加 <strong>node.kubernetes.io/unschedulable: NoSchedule</strong> 容忍度到 <strong>DaemonSet Pods</strong>。在调度 DaemonSet Pod 时，默认调度器会忽略 <strong>unschedulable</strong> 节点。</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" target="_blank" rel="noopener">Kubernetes DaemonSet</a></li><li><a href="https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/" target="_blank" rel="noopener">Pod Priority and Preemption</a></li><li><a href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity" target="_blank" rel="noopener">Assigning Pods to Nodes: Affinity and anti-affinity</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;DaemonSet&lt;/strong&gt; 确保全部 (或者某些) 节点上运行一个 Pod 的副本。 当有节点加入集群时，也会为他们新增一个 Pod 。当有节点从集群移除时，这些 Pod 也会被回收。删除 DaemonSet 将会删除它创建的所有 Pod。&lt;/p&gt;</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://divinerapier.github.io/tags/kubernetes/"/>
    
    <category term="controllers" scheme="http://divinerapier.github.io/tags/controllers/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes StatefulSet</title>
    <link href="http://divinerapier.github.io/2020/10/27/kubernetes-statefulset/"/>
    <id>http://divinerapier.github.io/2020/10/27/kubernetes-statefulset/</id>
    <published>2020-10-27T03:58:31.000Z</published>
    <updated>2020-10-27T07:30:40.598Z</updated>
    
    <content type="html"><![CDATA[<p>StatefulSet 是用来管理有状态应用的工作负载 API 对象。</p><p>StatefulSet 用来管理 Deployment 和扩展一组 Pod，并且能为这些 Pod 提供序号和唯一性保证。</p><p>和 Deployment 相同的是，StatefulSet 管理了基于相同容器定义的一组 Pod。但和 Deployment 不同的是，StatefulSet 为它们的每个 Pod 维护了一个固定的 ID。这些 Pod 是基于相同的声明来创建的，但是不能相互替换：无论怎么调度，每个 Pod 都有一个永久不变的 ID。</p><p>StatefulSet 和其他控制器使用相同的工作模式。你在 StatefulSet 对象 中定义你期望的状态，然后 StatefulSet 的 控制器 就会通过各种更新来达到那种你想要的状态。</p><h2 id="使用-StatefulSets"><a href="#使用-StatefulSets" class="headerlink" title="使用 StatefulSets"></a>使用 StatefulSets</h2><p>StatefulSets 对于需要满足以下一个或多个需求的应用程序很有价值:</p><ul><li>稳定的、唯一的网络标识符。</li><li>稳定的、持久的存储。</li><li>有序的、优雅的部署和缩放。</li><li>有序的、自动的滚动更新。</li></ul><p>在上面，稳定意味着 Pod 调度或重调度的整个过程是有持久性的。如果应用程序不需要任何稳定的标识符或有序的部署、删除或伸缩，则应该使用由一组无状态的副本控制器提供的工作负载来部署应用程序，比如 Deployment 或者 ReplicaSet 可能更适用于您的无状态应用部署需要。</p><h2 id="限制"><a href="#限制" class="headerlink" title="限制"></a>限制</h2><ul><li>给定 Pod 的存储必须由 <a href="https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning/README.md" target="_blank" rel="noopener">PersistentVolume</a> 驱动 基于所请求的 <strong>storage class</strong> 来提供，或者由管理员预先提供。</li><li>删除或者收缩 StatefulSet 并 <strong>不会删除</strong> 它关联的存储卷。这样做是为了保证数据安全，它通常比自动清除 StatefulSet 所有相关的资源更有价值。</li><li>StatefulSet 当前需要 <a href="https://kubernetes.io/docs/concepts/services-networking/service/#headless-services" target="_blank" rel="noopener">Headless Services</a> 来负责 Pod 的网络标识。用户需要负责创建此服务。</li><li>当删除 StatefulSets 时，StatefulSet 不提供任何终止 Pod 的保证。为了实现 StatefulSet 中的 Pod 可以有序和优雅的终止，可以在删除之前将 StatefulSet 缩放为 0。</li><li>在默认 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies" target="_blank" rel="noopener">Pod 管理策略</a>(<strong>OrderedReady</strong>) 时使用 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#rolling-updates" target="_blank" rel="noopener">滚动更新</a>，可能进入需要 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#forced-rollback" target="_blank" rel="noopener">人工干预</a> 才能修复的损坏状态。</li></ul><h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><p>下面的示例演示了 StatefulSet 的组件。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">80</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.template.metadata.labels</span></span><br><span class="line">  <span class="attr">serviceName:</span> <span class="string">"nginx"</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span> <span class="comment"># by default is 1</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.selector.matchLabels</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">terminationGracePeriodSeconds:</span> <span class="number">10</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">k8s.gcr.io/nginx-slim:0.8</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">          <span class="attr">name:</span> <span class="string">web</span></span><br><span class="line">        <span class="attr">volumeMounts:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">www</span></span><br><span class="line">          <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line">  <span class="attr">volumeClaimTemplates:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">www</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line">      <span class="attr">storageClassName:</span> <span class="string">"my-storage-class"</span></span><br><span class="line">      <span class="attr">resources:</span></span><br><span class="line">        <span class="attr">requests:</span></span><br><span class="line">          <span class="attr">storage:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure><ul><li>名为 <strong>nginx</strong> 的 Headless Service 用来控制网络域名。</li><li>名为 <strong>web</strong> 的 StatefulSet 有一个 Spec，它表明将在独立的 3 个 Pod 副本中启动 nginx 容器。</li><li><strong>volumeClaimTemplates</strong> 将通过 PersistentVolumes 驱动提供的 <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/" target="_blank" rel="noopener">PersistentVolumes</a> 来提供稳定的存储。</li></ul><p>StatefulSet 对象的 <strong>name</strong> 必须是合法的 <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/names#dns-subdomain-names" target="_blank" rel="noopener">DNS 域名</a>。</p><h2 id="Pod-Selector"><a href="#Pod-Selector" class="headerlink" title="Pod Selector"></a>Pod Selector</h2><p>必须将 StatefullSet 的 <strong>.spec.selector</strong> 字段与 <strong>.spec.template.metadata.labels</strong> 设置相同的值。</p><p>在 Kubernetes 1.8 版本之前，忽略 <strong>.spec.selector</strong> 字段会获得默认设置值。在 1.8 及以后的版本中，未指定匹配的 Pod Selector 将在创建 StatefulSet 期间导致验证错误。</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/" target="_blank" rel="noopener">Kubernetes StatefulSet</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;StatefulSet 是用来管理有状态应用的工作负载 API 对象。&lt;/p&gt;
&lt;p&gt;StatefulSet 用来管理 Deployment 和扩展一组 Pod，并且能为这些 Pod 提供序号和唯一性保证。&lt;/p&gt;
&lt;p&gt;和 Deployment 相同的是，Stateful</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://divinerapier.github.io/tags/kubernetes/"/>
    
    <category term="controllers" scheme="http://divinerapier.github.io/tags/controllers/"/>
    
  </entry>
  
  <entry>
    <title>Kubernetes Deployment</title>
    <link href="http://divinerapier.github.io/2020/10/27/kubernetes-deployment/"/>
    <id>http://divinerapier.github.io/2020/10/27/kubernetes-deployment/</id>
    <published>2020-10-27T02:48:23.000Z</published>
    <updated>2020-10-27T06:43:19.458Z</updated>
    
    <content type="html"><![CDATA[<p>一个 Deployment 控制器为 <a href="https://kubernetes.io/docs/concepts/workloads/pods/" target="_blank" rel="noopener">Pods</a> 和 <a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/" target="_blank" rel="noopener">ReplicaSets</a> 提供声明式的更新能力。</p><p>用户负责描述 Deployment 中的 <strong>目标状态</strong>，而 Deployment 控制器以受控速率更改 <strong>实际状态</strong>，使其变为 <strong>期望状态</strong>。用户可以定义 Deployment 以创建新的 ReplicaSet，或删除现有 Deployment， 并通过新的 Deployment 接收(adopt)其资源。</p><blockquote><p><strong>说明</strong>： 不要管理 Deployment 所拥有的 ReplicaSet 。 如果存在下面未覆盖的使用场景，请考虑在 Kubernetes 仓库中提出 Issue。</p></blockquote><h2 id="用例"><a href="#用例" class="headerlink" title="用例"></a>用例</h2><p>以下是 Deployments 的典型用例：</p><ul><li><a href="#Deployment">创建 Deployment 使 ReplicaSet 上线(rollout)</a>。 ReplicaSet 在后台创建 Pods。 检查 ReplicaSet 的上线状态，查看其是否成功。</li><li>通过更新 Deployment 的 PodTemplateSpec，声明 Pod 的新状态 。 新的 ReplicaSet 会被创建，Deployment 以受控速率将 Pod 从旧 ReplicaSet 迁移到新 ReplicaSet。 每个新的 ReplicaSet 都会更新 Deployment 的修订版本。</li><li>如果 Deployment 的当前状态不稳定，回滚到较早的 Deployment 版本。 每次回滚都会更新 Deployment 的修订版本。</li><li>扩大 Deployment 规模以承担更多负载。</li><li>暂停 Deployment 以应用对 PodTemplateSpec 所作的多项修改， 然后恢复其执行以启动新的上线版本。</li><li>使用 Deployment 状态 来判定上线过程是否出现停滞。</li><li>清理较旧的不再需要的 ReplicaSet。</li></ul><h2 id="创建-Deployment"><a href="#创建-Deployment" class="headerlink" title="创建 Deployment"></a>创建 Deployment</h2><p>下面是 Deployment 示例。Deployment 创建一个 ReplicaSet，负责启动三个 <strong>nginx</strong> Pods:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">nginx-deployment</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">replicas:</span> <span class="number">3</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">matchLabels:</span></span><br><span class="line">      <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">  <span class="attr">template:</span></span><br><span class="line">    <span class="attr">metadata:</span></span><br><span class="line">      <span class="attr">labels:</span></span><br><span class="line">        <span class="attr">app:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="attr">spec:</span></span><br><span class="line">      <span class="attr">containers:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">nginx</span></span><br><span class="line">        <span class="attr">image:</span> <span class="string">nginx:1.14.2</span></span><br><span class="line">        <span class="attr">ports:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure><p>在该例中:</p><ul><li><p>创建名为 <strong>nginx-deployment</strong> (由 <strong>.metadata.name</strong> 字段标明) 的 Deployment。</p></li><li><p>该 Deployment 创建三个 (由 <strong>.spec.replicas</strong> 字段标明) Pod 副本。</p></li><li><p><strong>.spec.selector</strong> 字段定义 Deployment 如何查找要管理的 Pods。 在这里，你只需选择在 Pod 模板中定义的标签（app: nginx）。 不过，更复杂的选择规则是也可能的，只要 Pod 模板</p><blockquote><p><strong>说明</strong>： <strong>matchLabels</strong> 字段是 {key,value} 字典映射。在 <strong>matchLabels</strong> 映射中的单个 {key,value} 映射等效于 <strong>matchExpressions</strong> 中的一个元素，即其 key 字段是 “key”，operator 为 “In”，value 数组仅包含 “value”。在 <strong>matchLabels</strong> 和 <strong>matchExpressions</strong> 中给出的所有条件都必须满足才能匹配。</p></blockquote></li><li><p><strong>.spec.template</strong> 字段包含以下子字段:</p><ul><li>使用 <strong>.metadata.labels</strong> 字段为 Pod 设置标签 <strong>app: nginx</strong></li><li><strong>.template.spec</strong> 字段表示 Pod 的模板，指示 Pods 运行一个 <strong>nginx</strong> 容器，该容器运行 <strong>nginx:1.14.2</strong> 镜像。</li><li>创建一个容器，使用 <strong>.spec.template.spec.containers[0].name</strong> 字段 <strong>nginx</strong> 作为名字</li></ul></li></ul><p>开始之前，请确保的 Kubernetes 集群已启动并运行。 按照以下步骤创建上述 Deployment:</p><ol><li><p>通过运行以下命令创建 Deployment:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml</span><br></pre></td></tr></table></figure></li><li><p>检查 Deployment 是否已创建。如果仍在创建 Deployment， 则输出类似于:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get deployments</span><br><span class="line"></span><br><span class="line">NAME               READY   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   0/3     0            0           1s</span><br></pre></td></tr></table></figure><p> 在检查集群中的 Deployment 时，所显示的字段有：</p><ul><li>NAME 列出了集群中 Deployment 的名称。</li><li>READY 显示应用程序的可用的 <strong>副本</strong> 数。显示的模式是“就绪个数/期望个数”。</li><li>UP-TO-DATE 显示为了打到期望状态已经更新的副本数。</li><li>AVAILABLE 显示应用可供用户使用的副本数。</li><li>AGE 显示应用程序运行的时间。<br>请注意期望副本数是根据 <strong>.spec.replicas</strong> 字段设置 3。</li></ul></li><li><p>查看 Deployment 上线状态:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout status deployment.v1.apps/nginx-deployment</span><br><span class="line"></span><br><span class="line">Waiting <span class="keyword">for</span> rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line">deployment <span class="string">"nginx-deployment"</span> successfully rolled out</span><br></pre></td></tr></table></figure></li><li><p>查看 Deployment 创建的 ReplicaSet (rs):</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get rs</span><br><span class="line"></span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-75675f5897   3         3         3       18s</span><br></pre></td></tr></table></figure><p> ReplicaSet 输出中包含以下字段:</p><ul><li>NAME 列出名字空间中 ReplicaSet 的名称；</li><li>DESIRED 显示应用的期望副本个数，即在创建 Deployment 时所定义的值。 此为期望状态；</li><li>CURRENT 显示当前运行状态中的副本个数；</li><li>READY 显示应用中有多少副本可以为用户提供服务；</li><li>AGE 显示应用已经运行的时间长度。<blockquote><p><strong>注意</strong>: ReplicaSet 的名称始终被格式化为 <strong>[Deployment名称]-[随机字符串]</strong>。 其中的随机字符串是使用 <strong>pod-template-hash</strong> 作为种子随机生成的。</p></blockquote></li></ul></li><li><p>查看每个 Pod 自动生成的标签:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods --show-labels</span><br><span class="line"></span><br><span class="line">NAME                                READY     STATUS    RESTARTS   AGE       LABELS</span><br><span class="line">nginx-deployment-75675f5897-7ci7o   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453</span><br><span class="line">nginx-deployment-75675f5897-kzszj   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453</span><br><span class="line">nginx-deployment-75675f5897-qqcnn   1/1       Running   0          18s       app=nginx,pod-template-hash=3123191453</span><br></pre></td></tr></table></figure><p> 所创建的 ReplicaSet 确保总是存在三个 <strong>nginx</strong> Pod。</p></li></ol><blockquote><p><strong>说明</strong>: 必须在 Deployment 中指定适当的 <strong>.spec.selector</strong> 和 <strong>.spec.template.metadata.labels</strong>。不要与其他控制器重叠。 Kubernetes 不会阻止这样做，但是如果多个控制器具有重叠的 selector，它们可能会发生冲突 执行难以预料的操作。</p></blockquote><h3 id="Pod-template-hash-标签"><a href="#Pod-template-hash-标签" class="headerlink" title="Pod-template-hash 标签"></a>Pod-template-hash 标签</h3><blockquote><p><strong>注意</strong>: 不要更改此标签</p></blockquote><p>Deployment 控制器将 <strong>pod-template-hash</strong> 标签添加到 Deployment 所创建或接收(adopt) 的 每个 ReplicaSet 。</p><p>此标签可确保 Deployment 的子 ReplicaSets 不重叠。 标签是通过对 ReplicaSet 的 PodTemplate 进行哈希处理。 所生成的哈希值被添加到 ReplicaSet 的 <strong>selector</strong>、Pod 的 <strong>label</strong>，并存在于在 ReplicaSet 可能拥有的任何现有 Pod 中。</p><h2 id="更新-Deployment"><a href="#更新-Deployment" class="headerlink" title="更新 Deployment"></a>更新 Deployment</h2><blockquote><p><strong>说明</strong>: 仅当 Deployment 的 <strong>.spec.template</strong> 发生改变时，例如模板的标签或容器镜像被更新，才会触发 Deployment 上线。其他更新(如对 Deployment 执行扩缩容的操作) 不会触发上线动作。</p></blockquote><p>按照以下步骤更新 Deployment:</p><ol><li><p>更新 <strong>nginx</strong> Pod 镜像，从 <strong>nginx:1.14.2</strong> 到 <strong>nginx:1.16.1</strong>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl --record deployment.apps/nginx-deployment <span class="built_in">set</span> image \</span><br><span class="line">   deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1</span><br><span class="line"></span><br><span class="line">deployment.apps/nginx-deployment image updated</span><br></pre></td></tr></table></figure><p>或者使用下面的命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl <span class="built_in">set</span> image deployment/nginx-deployment nginx=nginx:1.16.1 --record</span><br><span class="line"></span><br><span class="line">deployment.apps/nginx-deployment image updated</span><br></pre></td></tr></table></figure><p>或者，可以 <strong>edit</strong> Deployment 并将 <strong>.spec.template.spec.containers[0].image</strong> 从 <strong>nginx:1.14.2</strong> 更改至 <strong>nginx:1.16.1</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl edit deployment.v1.apps/nginx-deployment</span><br><span class="line"></span><br><span class="line">deployment.apps/nginx-deployment edited</span><br></pre></td></tr></table></figure></li><li><p>查看上线状态，运行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl rollout status deployment.v1.apps/nginx-deployment</span><br><span class="line"></span><br><span class="line">Waiting <span class="keyword">for</span> rollout to finish: 2 out of 3 new replicas have been updated...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"></span><br><span class="line">deployment <span class="string">"nginx-deployment"</span> successfully rolled out</span><br></pre></td></tr></table></figure></li></ol><p>获取关于已更新的 Deployment 的更多信息:</p><ul><li><p>查看 Deployment:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get deployments</span><br><span class="line"></span><br><span class="line">NAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">nginx-deployment   3         3         3            3           36s</span><br></pre></td></tr></table></figure></li><li><p>查看 Deployment 通过创建新的 ReplicaSet:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get rs</span><br><span class="line"></span><br><span class="line">NAME                          DESIRED   CURRENT   READY   AGE</span><br><span class="line">nginx-deployment-1564180365   3         3         3       6s</span><br><span class="line">nginx-deployment-2035384211   0         0         0       36s</span><br></pre></td></tr></table></figure></li><li><p>查看 Deployment 的 Pod</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods</span><br><span class="line"></span><br><span class="line">NAME                                READY     STATUS    RESTARTS   AGE</span><br><span class="line">nginx-deployment-1564180365-khku8   1/1       Running   0          14s</span><br><span class="line">nginx-deployment-1564180365-nacti   1/1       Running   0          14s</span><br><span class="line">nginx-deployment-1564180365-z9gth   1/1       Running   0          14s</span><br></pre></td></tr></table></figure><p>Deployment 可确保在更新时仅关闭一定数量的 Pod。默认情况下，它确保至少所需 Pods 数量的 <strong>75%</strong> 处于运行状态 (最大不可用比例为 25%)。</p><p>Deployment 还确保所创建 Pod 的数量只比期望 Pods 的数量超出一定数值。默认情况下，Deployment 可确保实际启动的 Pod 个数最大为期望值的 125%。</p></li><li><p>获取 Deployment 的更多信息:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl describe deployments</span><br></pre></td></tr></table></figure></li></ul><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://kubernetes.io/docs/concepts/workloads/pods/" target="_blank" rel="noopener">Kubernetes Pods</a></li><li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/" target="_blank" rel="noopener">Kubernetes ReplicaSets</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;一个 Deployment 控制器为 &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/pods/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Pods&lt;/a&gt; 和 &lt;a href=&quot;https</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://divinerapier.github.io/tags/kubernetes/"/>
    
    <category term="controllers" scheme="http://divinerapier.github.io/tags/controllers/"/>
    
  </entry>
  
  <entry>
    <title>/opt/cni - readonly filesystem</title>
    <link href="http://divinerapier.github.io/2020/10/26/opt-cni-is-readonly-directory/"/>
    <id>http://divinerapier.github.io/2020/10/26/opt-cni-is-readonly-directory/</id>
    <published>2020-10-26T03:44:37.000Z</published>
    <updated>2020-10-26T04:21:08.386Z</updated>
    
    <content type="html"><![CDATA[<p>在部署 <a href="https://docs.projectcalico.org/getting-started/kubernetes/flannel/flannel" target="_blank" rel="noopener">Canal</a> 时遇到如下错误:</p><ol><li><p>查看 <strong>Pod</strong> 状态:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods --all-namespaces</span><br><span class="line"></span><br><span class="line">NAMESPACE     NAME                                                              READY   STATUS                   RESTARTS   AGE</span><br><span class="line">kube-system   canal-5qk26                                                       0/2     Init:RunContainerError   0          10m</span><br><span class="line">kube-system   kube-proxy-tt2qn                                                  0/1     CrashLoopBackOff         10         11m</span><br></pre></td></tr></table></figure></li><li><p>查看 <strong>canal-5qk26</strong> 事件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system describe pod canal-5qk26</span><br><span class="line"></span><br><span class="line">Events:</span><br><span class="line">  Type     Reason          Age                     From                Message</span><br><span class="line">  ----     ------          ----                    ----                -------</span><br><span class="line">  Normal   Scheduled       6m41s                   default-scheduler   Successfully assigned kube-system/canal-5qk26 to ubuntu-01</span><br><span class="line">  Warning  Failed          6m40s                   kubelet, ubuntu-01  Error: failed to start container <span class="string">"install-cni"</span>: Error response from daemon: can<span class="string">'t join IPC of container 1f3affaa9eba3f1087ac2309f7c4147a54e2cbad09be733e9c394ce7a8ba583b: container 1f3affaa9eba3f1087ac2309f7c4147a54e2cbad09be733e9c394ce7a8ba583b is not running</span></span><br><span class="line"><span class="string">  Warning  Failed          6m39s                   kubelet, ubuntu-01  Error: failed to start container "install-cni": Error response from daemon: cannot join network of a non running container: 1861c340dfadba101b333af1163329a88a8e02fd25e5d657b4e0954acd09d3d5</span></span><br><span class="line"><span class="string">  Warning  Failed          6m37s                   kubelet, ubuntu-01  Error: failed to start container "install-cni": Error response from daemon: error while creating mount source path '</span>/opt/cni/bin<span class="string">': mkdir /opt/cni: read-only file system</span></span><br><span class="line"><span class="string">  Warning  BackOff         6m34s (x3 over 6m38s)   kubelet, ubuntu-01  Back-off restarting failed container</span></span><br><span class="line"><span class="string">  Normal   Pulled          6m33s (x5 over 6m40s)   kubelet, ubuntu-01  Container image "calico/cni:v3.16.4" already present on machine</span></span><br><span class="line"><span class="string">  Normal   Created         6m33s (x5 over 6m40s)   kubelet, ubuntu-01  Created container install-cni</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Normal   SandboxChanged  100s (x269 over 6m39s)  kubelet, ubuntu-01  Pod sandbox changed, it will be killed and re-created.</span></span><br></pre></td></tr></table></figure></li><li><p>查看 <strong>kube-proxy-tt2qn</strong> 事件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl -n kube-system describe pod kube-proxy-tt2qn</span><br><span class="line"></span><br><span class="line">Events:</span><br><span class="line">  Type     Reason          Age                      From                Message</span><br><span class="line">  ----     ------          ----                     ----                -------</span><br><span class="line">  Normal   Scheduled       11m                      default-scheduler   Successfully assigned kube-system/kube-proxy-tt2qn to ubuntu-01</span><br><span class="line">  Normal   Pulled          11m (x2 over 11m)        kubelet, ubuntu-01  Container image <span class="string">"registry.aliyuncs.com/google_containers/kube-proxy:v1.19.3"</span> already present on machine</span><br><span class="line">  Normal   Created         11m (x2 over 11m)        kubelet, ubuntu-01  Created container kube-proxy</span><br><span class="line">  Warning  Failed          11m                      kubelet, ubuntu-01  Error: failed to start container <span class="string">"kube-proxy"</span>: Error response from daemon: cannot join network of a non running container: 119388927b173ad23226c1049db0c1269ada343b133774807a1615cc79442246</span><br><span class="line">  Warning  BackOff         11m (x9 over 11m)        kubelet, ubuntu-01  Back-off restarting failed container</span><br><span class="line">  Normal   SandboxChanged  11m (x10 over 11m)       kubelet, ubuntu-01  Pod sandbox changed, it will be killed and re-created.</span><br></pre></td></tr></table></figure></li><li><p>查看 <strong>Worker</strong> 节点上 <strong>Kubelet</strong> 与 <strong>Docker</strong> 日志:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ journalctl -f</span><br><span class="line"></span><br><span class="line">  -- Logs begin at Mon 2020-10-19 10:09:50 UTC. --</span><br><span class="line">  Oct 26 02:31:35 ubuntu-01 docker.dockerd[1781]: time=<span class="string">"2020-10-26T02:31:35.429587085Z"</span> level=error msg=<span class="string">"Handler for POST /v1.40/containers/aef879b89cd75d23249e76091a4716c1303855b904979e983920aae02da01d18/start returned error: error while creating mount source path '/opt/cni/bin': mkdir /opt/cni: read-only file system"</span></span><br><span class="line">  Oct 26 02:31:35 ubuntu-01 kubelet[281110]: E1026 02:31:35.474035  281110 remote_runtime.go:248] StartContainer <span class="string">"aef879b89cd75d23249e76091a4716c1303855b904979e983920aae02da01d18"</span> from runtime service failed: rpc error: code = Unknown desc = failed to start container <span class="string">"aef879b89cd75d23249e76091a4716c1303855b904979e983920aae02da01d18"</span>: Error response from daemon: error <span class="keyword">while</span> creating mount <span class="built_in">source</span> path <span class="string">'/opt/cni/bin'</span>: mkdir /opt/cni: <span class="built_in">read</span>-only file system</span><br><span class="line">  Oct 26 02:31:35 ubuntu-01 kubelet[281110]: E1026 02:31:35.474175  281110 pod_workers.go:191] Error syncing pod 5f45d450-c4e9-45dc-b2c6-52a95570ba71 (<span class="string">"canal-5qk26_kube-system(5f45d450-c4e9-45dc-b2c6-52a95570ba71)"</span>), skipping: failed to <span class="string">"StartContainer"</span> <span class="keyword">for</span> <span class="string">"install-cni"</span> with RunContainerError: <span class="string">"failed to start container \"aef879b89cd75d23249e76091a4716c1303855b904979e983920aae02da01d18\": Error response from daemon: error while creating mount source path '/opt/cni/bin': mkdir /opt/cni: read-only file system"</span></span><br><span class="line">  Oct 26 02:31:36 ubuntu-01 audit[315954]: AVC apparmor=<span class="string">"DENIED"</span> operation=<span class="string">"exec"</span> info=<span class="string">"no new privs"</span> error=-1 profile=<span class="string">"snap.docker.dockerd"</span> name=<span class="string">"/pause"</span> pid=315954 comm=<span class="string">"runc:[2:INIT]"</span> requested_mask=<span class="string">"x"</span> denied_mask=<span class="string">"x"</span> fsuid=0 ouid=0 target=<span class="string">"docker-default"</span></span><br><span class="line">  Oct 26 02:31:36 ubuntu-01 kernel: audit: <span class="built_in">type</span>=1400 audit(1603679496.465:6039): apparmor=<span class="string">"DENIED"</span> operation=<span class="string">"exec"</span> info=<span class="string">"no new privs"</span> error=-1 profile=<span class="string">"snap.docker.dockerd"</span> name=<span class="string">"/pause"</span> pid=315954 comm=<span class="string">"runc:[2:INIT]"</span> requested_mask=<span class="string">"x"</span> denied_mask=<span class="string">"x"</span> fsuid=0 ouid=0 target=<span class="string">"docker-default"</span></span><br><span class="line">  Oct 26 02:31:36 ubuntu-01 kubelet[281110]: W1026 02:31:36.635730  281110 cni.go:239] Unable to update cni config: no networks found <span class="keyword">in</span> /etc/cni/net.d</span><br></pre></td></tr></table></figure></li></ol><p>根据上述日志信息，可以确认根本错误出现在 <strong>Docker</strong> 中:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">error while creating mount source path &#39;&#x2F;opt&#x2F;cni&#x2F;bin&#39;: mkdir &#x2F;opt&#x2F;cni: read-only file system</span><br></pre></td></tr></table></figure><p>但宿主机目录 <strong>/opt/cni</strong> 的权限为:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">stat</span> /opt/cni/</span><br><span class="line"></span><br><span class="line">  File: /opt/cni/</span><br><span class="line">  Size: 4096            Blocks: 8          IO Block: 4096   directory</span><br><span class="line">Device: fd00h/64768d    Inode: 917533      Links: 3</span><br><span class="line">Access: (0755/drwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Access: 2020-10-26 01:41:07.222221020 +0000</span><br><span class="line">Modify: 2020-10-20 13:00:36.461719609 +0000</span><br><span class="line">Change: 2020-10-20 13:00:36.461719609 +0000</span><br><span class="line"> Birth: -</span><br></pre></td></tr></table></figure><p>因此，推测为 <strong>Docker</strong> 服务的问题。最终，通过重启 <strong>Docker</strong> 解决问题:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl restart docker.service</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在部署 &lt;a href=&quot;https://docs.projectcalico.org/getting-started/kubernetes/flannel/flannel&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Canal&lt;/a&gt; 时遇到如下错误:</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://divinerapier.github.io/tags/kubernetes/"/>
    
    <category term="faq" scheme="http://divinerapier.github.io/tags/faq/"/>
    
  </entry>
  
  <entry>
    <title>MPI Operator</title>
    <link href="http://divinerapier.github.io/2020/10/24/mpi-operator/"/>
    <id>http://divinerapier.github.io/2020/10/24/mpi-operator/</id>
    <published>2020-10-24T10:17:12.000Z</published>
    <updated>2020-11-18T05:13:56.766Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>部署默认配置的 <strong>mpi-operator</strong>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/kubeflow/mpi-operator</span><br><span class="line"><span class="built_in">cd</span> mpi-operator</span><br><span class="line">kubectl create -f deploy/v1/mpi-operator.yaml</span><br></pre></td></tr></table></figure><p>验证是否安装成功:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get crd</span><br><span class="line"><span class="comment"># NAME                                          CREATED AT</span></span><br><span class="line"><span class="comment"># mpijobs.kubeflow.org                          2020-10-23T08:40:15Z</span></span><br></pre></td></tr></table></figure><h3 id="参数选项"><a href="#参数选项" class="headerlink" title="参数选项"></a>参数选项</h3><p>在使用 <strong>v1</strong> 版本时，需要注意几个选项:</p><ul><li><strong>-namespace</strong>: 不为空时，只监控指定 <strong>namespace</strong> 的 <strong>MPIJob</strong>，否则将监控所有的 <strong>namespace</strong></li><li><strong>-gang-scheduling</strong>: 指定使用的 <strong>gang scheduler</strong> 的名字，此时会启动 <strong>gang scheduling</strong> 调度策略</li><li><strong>launcher-runs-workloads</strong>: 在 <strong>launcher</strong> 拥有 <strong>GPU</strong> 时执行任务</li></ul><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>创建一个 <strong>MPIJob</strong> 的配置文件:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeflow.org/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">MPIJob</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">openmpi-helloworld</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">slotsPerWorker:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">cleanPodPolicy:</span> <span class="string">Running</span></span><br><span class="line">  <span class="attr">mpiReplicaSpecs:</span></span><br><span class="line">    <span class="attr">Launcher:</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">1</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">         <span class="attr">spec:</span></span><br><span class="line">           <span class="attr">containers:</span></span><br><span class="line">           <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">divinerapier/openmpi-helloworld:0.0.1</span></span><br><span class="line">             <span class="attr">name:</span> <span class="string">openmpi-helloworld</span></span><br><span class="line">             <span class="attr">command:</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">mpirun</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">--allow-run-as-root</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">-np</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">"2"</span></span><br><span class="line">             <span class="bullet">-</span> <span class="string">/helloworld/mpi_hello_world</span></span><br><span class="line">             <span class="attr">resources:</span></span><br><span class="line">               <span class="attr">request:</span></span><br><span class="line">                <span class="attr">cpu:</span> <span class="number">0.1</span></span><br><span class="line">                <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">               <span class="attr">limits:</span></span><br><span class="line">                 <span class="attr">cpu:</span> <span class="number">0.1</span></span><br><span class="line">                 <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">    <span class="attr">Worker:</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">      <span class="attr">template:</span></span><br><span class="line">        <span class="attr">spec:</span></span><br><span class="line">          <span class="attr">containers:</span></span><br><span class="line">          <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">divinerapier/openmpi-helloworld:0.0.1</span></span><br><span class="line">            <span class="attr">name:</span> <span class="string">openmpi-helloworld</span></span><br><span class="line">            <span class="attr">resources:</span></span><br><span class="line">              <span class="attr">request:</span></span><br><span class="line">                <span class="attr">cpu:</span> <span class="number">0.1</span></span><br><span class="line">                <span class="attr">memory:</span> <span class="string">1Gi</span></span><br><span class="line">              <span class="attr">limits:</span></span><br><span class="line">                <span class="attr">cpu:</span> <span class="number">0.1</span></span><br><span class="line">                <span class="attr">memory:</span> <span class="string">1Gi</span></span><br></pre></td></tr></table></figure><p>部署到 <strong>Kubernetes</strong> 上:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f ./openmpi-helloworld.yml</span><br></pre></td></tr></table></figure><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://github.com/kubeflow/mpi-operator" target="_blank" rel="noopener">GitHub: MPI Operator</a></li><li><a href="https://medium.com/kubeflow/introduction-to-kubeflow-mpi-operator-and-industry-adoption-296d5f2e6edc" target="_blank" rel="noopener">Introduction to Kubeflow MPI Operator and Industry Adoption</a></li><li><a href="https://www.kubeflow.org/docs/components/training/mpi/" target="_blank" rel="noopener">MPI Training</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;p&gt;部署默认配置的 &lt;strong&gt;mpi-operator&lt;/strong&gt;:&lt;/p&gt;
&lt;figure class=&quot;highlight ba</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://divinerapier.github.io/tags/kubernetes/"/>
    
    <category term="mpi" scheme="http://divinerapier.github.io/tags/mpi/"/>
    
    <category term="operator" scheme="http://divinerapier.github.io/tags/operator/"/>
    
  </entry>
  
  <entry>
    <title>在 Docker 中使用 OpenMPI</title>
    <link href="http://divinerapier.github.io/2020/10/24/openmpi-in-docker/"/>
    <id>http://divinerapier.github.io/2020/10/24/openmpi-in-docker/</id>
    <published>2020-10-24T08:57:06.000Z</published>
    <updated>2020-10-26T04:06:45.546Z</updated>
    
    <content type="html"><![CDATA[<h2 id="构建-Base-镜像"><a href="#构建-Base-镜像" class="headerlink" title="构建 Base 镜像"></a>构建 Base 镜像</h2><p>基于 <strong>Ubuntu 20.04 + OpenMPI 4.0.5</strong> 构建 <strong>Base</strong> 镜像:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu:<span class="number">20.04</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt update</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt install -y wget gcc g++ make</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install OpenSSH for MPI to communicate between containers</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get install -y --no-install-recommends openssh-client openssh-server &amp;&amp; \</span></span><br><span class="line"><span class="bash">    mkdir -p /var/run/sshd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Allow OpenSSH to talk to containers without asking for confirmation</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> cat /etc/ssh/ssh_config | grep -v StrictHostKeyChecking &gt; /etc/ssh/ssh_config.new &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">echo</span> <span class="string">"    StrictHostKeyChecking no"</span> &gt;&gt; /etc/ssh/ssh_config.new &amp;&amp; \</span></span><br><span class="line"><span class="bash">    mv /etc/ssh/ssh_config.new /etc/ssh/ssh_config</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Install Open MPI</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir /tmp/openmpi &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">cd</span> /tmp/openmpi &amp;&amp; \</span></span><br><span class="line"><span class="bash">    wget https://www.open-mpi.org/software/ompi/v4.0/downloads/openmpi-4.0.5.tar.gz &amp;&amp; \</span></span><br><span class="line"><span class="bash">    tar zxf openmpi-4.0.5.tar.gz &amp;&amp; \</span></span><br><span class="line"><span class="bash">    <span class="built_in">cd</span> openmpi-4.0.5 &amp;&amp; \</span></span><br><span class="line"><span class="bash">    ./configure --<span class="built_in">enable</span>-orterun-prefix-by-default &amp;&amp; \</span></span><br><span class="line"><span class="bash">    make -j $(nproc) all &amp;&amp; \</span></span><br><span class="line"><span class="bash">    make install &amp;&amp; \</span></span><br><span class="line"><span class="bash">    ldconfig</span></span><br></pre></td></tr></table></figure><h3 id="发布镜像"><a href="#发布镜像" class="headerlink" title="发布镜像"></a>发布镜像</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker build -t divinerapier/openmpi:4.0.5 -f=./dockerfile .</span><br><span class="line">docker push divinerapier/openmpi:4.0.5</span><br></pre></td></tr></table></figure><h2 id="应用程序"><a href="#应用程序" class="headerlink" title="应用程序"></a>应用程序</h2><h3 id="程序代码"><a href="#程序代码" class="headerlink" title="程序代码"></a>程序代码</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mpi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化 MPI 环境</span></span><br><span class="line">    MPI_Init(<span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过调用以下方法来得到所有可以工作的进程数量</span></span><br><span class="line">    <span class="keyword">int</span> world_size;</span><br><span class="line">    MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 得到当前进程的秩</span></span><br><span class="line">    <span class="keyword">int</span> world_rank;</span><br><span class="line">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 得到当前进程的名字</span></span><br><span class="line">    <span class="keyword">char</span> processor_name[MPI_MAX_PROCESSOR_NAME];</span><br><span class="line">    <span class="keyword">int</span> name_len;</span><br><span class="line">    MPI_Get_processor_name(processor_name, &amp;name_len);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印一条带有当前进程名字，秩以及</span></span><br><span class="line">    <span class="comment">// 整个 communicator 的大小的 hello world 消息。</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"Hello world from processor %s, rank %d out of %d processors\n"</span>,</span><br><span class="line">           processor_name, world_rank, world_size);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放 MPI 的一些资源</span></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">MPICC ?= mpicc</span><br><span class="line"></span><br><span class="line"><span class="section">all: build</span></span><br><span class="line"></span><br><span class="line"><span class="section">build: main.c</span></span><br><span class="line">    <span class="variable">$(MPICC)</span> -o mpi_hello_world main.c</span><br><span class="line"></span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">    rm -rf mpi_hello_world</span><br></pre></td></tr></table></figure><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> divinerapier/openmpi:<span class="number">4.0</span>.<span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./ /helloworld</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">cd</span> /helloworld \</span></span><br><span class="line"><span class="bash">  &amp;&amp; make</span></span><br></pre></td></tr></table></figure><h3 id="运行应用程序"><a href="#运行应用程序" class="headerlink" title="运行应用程序"></a>运行应用程序</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker build -t divinerapier/openmpi-helloworld:0.0.1 -f=./dockerfile .</span><br><span class="line">docker run --rm -it divinerapier/openmpi-helloworld:0.0.1 mpirun -allow-run-as-root -np 4 /helloworld/mpi_hello_world</span><br><span class="line"><span class="comment"># Hello world from processor fa74677bda6b, rank 0 out of 4 processors</span></span><br><span class="line"><span class="comment"># Hello world from processor fa74677bda6b, rank 1 out of 4 processors</span></span><br><span class="line"><span class="comment"># Hello world from processor fa74677bda6b, rank 2 out of 4 processors</span></span><br><span class="line"><span class="comment"># Hello world from processor fa74677bda6b, rank 3 out of 4 processors</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;构建-Base-镜像&quot;&gt;&lt;a href=&quot;#构建-Base-镜像&quot; class=&quot;headerlink&quot; title=&quot;构建 Base 镜像&quot;&gt;&lt;/a&gt;构建 Base 镜像&lt;/h2&gt;&lt;p&gt;基于 &lt;strong&gt;Ubuntu 20.04 + OpenMPI 4.0.</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>升级 Ubuntu 发行版</title>
    <link href="http://divinerapier.github.io/2020/10/20/upgrade-ubuntu-release/"/>
    <id>http://divinerapier.github.io/2020/10/20/upgrade-ubuntu-release/</id>
    <published>2020-10-20T08:05:06.000Z</published>
    <updated>2020-10-20T08:15:06.347Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Install all available updates for your release before upgrading.</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update &amp;&amp; sudo apt upgrade -y</span><br></pre></td></tr></table></figure><p><strong>Reboot system.</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><p><strong>Install the Ubuntu update tool.</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y update-manager-core</span><br></pre></td></tr></table></figure><p><strong>Start the upgrade procdure.</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="keyword">do</span>-release-upgrade</span><br></pre></td></tr></table></figure><p>不建议升级过程通过 <strong>ssh</strong> 连接运行，可以运行在 <strong>tmux</strong> 会话中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ sudo <span class="keyword">do</span>-release-upgrade</span><br><span class="line">Checking <span class="keyword">for</span> a new Ubuntu release</span><br><span class="line">Get:1 Upgrade tool signature [1,554 B]</span><br><span class="line">Get:2 Upgrade tool [1,336 kB]</span><br><span class="line">Fetched 1,338 kB <span class="keyword">in</span> 0s (0 B/s)</span><br><span class="line">authenticate <span class="string">'focal.tar.gz'</span> against <span class="string">'focal.tar.gz.gpg'</span></span><br><span class="line">extracting <span class="string">'focal.tar.gz'</span></span><br><span class="line"></span><br><span class="line">Reading cache</span><br><span class="line"></span><br><span class="line">Checking package manager</span><br><span class="line"></span><br><span class="line">Continue running under SSH?</span><br><span class="line"></span><br><span class="line">This session appears to be running under ssh. It is not recommended</span><br><span class="line">to perform a upgrade over ssh currently because <span class="keyword">in</span> <span class="keyword">case</span> of failure it</span><br><span class="line">is harder to recover.</span><br><span class="line"></span><br><span class="line">If you <span class="built_in">continue</span>, an additional ssh daemon will be started at port</span><br><span class="line"><span class="string">'1022'</span>.</span><br><span class="line">Do you want to <span class="built_in">continue</span>?</span><br><span class="line"></span><br><span class="line">Continue [yN]</span><br></pre></td></tr></table></figure><p><strong>Reboot the box.</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo reboot</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Install all available updates for your release before upgrading.&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class</summary>
      
    
    
    
    
    <category term="linux" scheme="http://divinerapier.github.io/tags/linux/"/>
    
    <category term="ubuntu" scheme="http://divinerapier.github.io/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>使用 kubeadm 创建 kubernetes 集群</title>
    <link href="http://divinerapier.github.io/2020/10/19/using-kubeadm-to-create-a-kubernetes-cluster/"/>
    <id>http://divinerapier.github.io/2020/10/19/using-kubeadm-to-create-a-kubernetes-cluster/</id>
    <published>2020-10-19T12:38:25.000Z</published>
    <updated>2020-10-26T04:14:58.976Z</updated>
    
    <content type="html"><![CDATA[<p>在 <strong>Ubuntu 20.04</strong> 系统上搭建 <strong>Kubernetes</strong> 集群。</p><h2 id="安装-Docker"><a href="#安装-Docker" class="headerlink" title="安装 Docker"></a>安装 Docker</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove docker docker-engine docker.io containerd runc</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y \</span><br><span class="line">    apt-transport-https \</span><br><span class="line">    ca-certificates \</span><br><span class="line">    curl \</span><br><span class="line">    gnupg-agent \</span><br><span class="line">    software-properties-common</span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line">sudo apt-key fingerprint 0EBFCD88</span><br><span class="line">sudo add-apt-repository \</span><br><span class="line">   <span class="string">"deb [arch=amd64] https://download.docker.com/linux/ubuntu \</span></span><br><span class="line"><span class="string">   <span class="variable">$(lsb_release -cs)</span> \</span></span><br><span class="line"><span class="string">   stable"</span></span><br><span class="line">sudo apt-get update --fix-missing</span><br><span class="line">sudo apt-get install -y docker-ce docker-ce-cli containerd.io</span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">  <span class="string">"log-driver"</span>: <span class="string">"json-file"</span>,</span><br><span class="line">  <span class="string">"log-opts"</span>: &#123;</span><br><span class="line">    <span class="string">"max-size"</span>: <span class="string">"100m"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"storage-driver"</span>: <span class="string">"overlay2"</span></span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo mkdir -p /etc/systemd/system/docker.service.d</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure><h2 id="下载-Kubernetes-相关程序"><a href="#下载-Kubernetes-相关程序" class="headerlink" title="下载 Kubernetes 相关程序"></a>下载 Kubernetes 相关程序</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install -y apt-transport-https curl</span><br><span class="line">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -</span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list</span><br><span class="line">deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main</span><br><span class="line">EOF</span><br><span class="line">sudo apt-get update --fix-missing</span><br><span class="line">sudo apt-get install -y kubelet kubeadm kubectl</span><br><span class="line">sudo apt-mark hold kubelet kubeadm kubectl</span><br></pre></td></tr></table></figure><h2 id="配置桥接网络防火墙"><a href="#配置桥接网络防火墙" class="headerlink" title="配置桥接网络防火墙"></a>配置桥接网络防火墙</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">sudo sysctl --system</span><br></pre></td></tr></table></figure><h2 id="关闭-swap"><a href="#关闭-swap" class="headerlink" title="关闭 swap"></a>关闭 swap</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 临时关闭</span></span><br><span class="line">swapoff -a</span><br><span class="line"></span><br><span class="line"><span class="comment"># 永久关闭，注释 swap 配置</span></span><br><span class="line">vi /etc/fstab</span><br></pre></td></tr></table></figure><h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop firewalld</span><br><span class="line">sudo systemctl <span class="built_in">disable</span> firewalld</span><br></pre></td></tr></table></figure><h2 id="关闭-selinux"><a href="#关闭-selinux" class="headerlink" title="关闭 selinux"></a>关闭 selinux</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo sed -i <span class="string">'s/enforcing/disabled/'</span> /etc/selinux/config</span><br><span class="line">sudo setenforce 0</span><br></pre></td></tr></table></figure><h2 id="拉取-gcr-镜像"><a href="#拉取-gcr-镜像" class="headerlink" title="拉取 gcr 镜像"></a>拉取 gcr 镜像</h2><p>需要在所有的 <strong>Master</strong> 节点与 <strong>Worker</strong> 节点拉取镜像。</p><p><strong>bash</strong> 环境使用如下脚本:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">image_list=$(kubeadm config images list)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image <span class="keyword">in</span> <span class="variable">$&#123;image_list&#125;</span> ; <span class="keyword">do</span></span><br><span class="line">  name=$(<span class="built_in">echo</span> <span class="variable">$&#123;image&#125;</span> | cut -d<span class="string">'/'</span> -f2)</span><br><span class="line">  docker pull registry.aliyuncs.com/google_containers/<span class="variable">$name</span></span><br><span class="line">  docker image tag registry.aliyuncs.com/google_containers/<span class="variable">$name</span> k8s.gcr.io/<span class="variable">$name</span></span><br><span class="line">  docker image rm registry.aliyuncs.com/google_containers/<span class="variable">$name</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p><strong>zsh</strong> 环境使用如下脚本:</p><figure class="highlight zsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">image_list=$(kubeadm config images list)</span><br><span class="line">images=(`<span class="built_in">echo</span> <span class="variable">$&#123;image_list&#125;</span> | tr <span class="string">'\n'</span> <span class="string">' '</span>`)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> image <span class="keyword">in</span> <span class="variable">$&#123;images&#125;</span> ; <span class="keyword">do</span></span><br><span class="line">  name=$(<span class="built_in">echo</span> <span class="variable">$&#123;image&#125;</span> | cut -d<span class="string">'/'</span> -f2)</span><br><span class="line">  docker pull registry.aliyuncs.com/google_containers/<span class="variable">$name</span></span><br><span class="line">  docker image tag registry.aliyuncs.com/google_containers/<span class="variable">$name</span> k8s.gcr.io/<span class="variable">$name</span></span><br><span class="line">  docker image rm registry.aliyuncs.com/google_containers/<span class="variable">$name</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h2 id="初始化-Master-节点"><a href="#初始化-Master-节点" class="headerlink" title="初始化 Master 节点"></a>初始化 Master 节点</h2><p>在 <strong>Master</strong> 节点执行命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">sudo kubeadm init \</span><br><span class="line">  --apiserver-advertise-address $(hostname -i) \</span><br><span class="line">  --pod-network-cidr 10.244.0.0/16 --v=5</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 192.168.50.5:6443 --token 7zjyq9.x3xkoatt6pb1cbsu \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:1c78c44bc57e6e887c5f81e7a9c6c3e52f098e1ba9255f5303ac78129d410774</span><br></pre></td></tr></table></figure><p>或者省略下载镜像步骤，直接创建集群:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo kubeadm init \</span><br><span class="line">  --apiserver-advertise-address=$(hostname -i) \</span><br><span class="line">  --image-repository registry.aliyuncs.com/google_containers \</span><br><span class="line">  --service-cidr=10.5.0.0/16 \</span><br><span class="line">  --pod-network-cidr=10.244.0.0/16</span><br></pre></td></tr></table></figure><p>然后配置 <strong>kubeconfig</strong>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><h2 id="配置网络"><a href="#配置网络" class="headerlink" title="配置网络"></a>配置网络</h2><h3 id="Calico"><a href="#Calico" class="headerlink" title="Calico"></a>Calico</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/manifests/canal.yaml</span><br></pre></td></tr></table></figure><h2 id="添加-Worker-节点"><a href="#添加-Worker-节点" class="headerlink" title="添加 Worker 节点"></a>添加 Worker 节点</h2><p>在 <strong>Worker</strong> 节点执行命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo kubeadm join 192.168.50.5:6443 --token 4n2pwp.hq9jyo3auaibma3q     --discovery-token-ca-cert-hash sha256:750da2c87a67b96bfec73ade40888d22b61e045fdd28bbb7a4ff2c6ce3e0309c</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run <span class="string">'kubectl get nodes'</span> on the control-plane to see this node join the cluster.</span><br></pre></td></tr></table></figure><h2 id="测试集群"><a href="#测试集群" class="headerlink" title="测试集群"></a>测试集群</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/website/master/content/en/examples/application/nginx-app.yaml</span><br></pre></td></tr></table></figure><h2 id="清理集群"><a href="#清理集群" class="headerlink" title="清理集群"></a>清理集群</h2><p>在期望清理的节点执行:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo kubeadm reset</span><br><span class="line">sudo rm -rf /etc/cni/net.d</span><br><span class="line">rm -rf ~/.kube</span><br></pre></td></tr></table></figure><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://docs.docker.com/engine/install/ubuntu/" target="_blank" rel="noopener">Install Docker Engine on Ubuntu</a></li><li><a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/" target="_blank" rel="noopener">Container runtimes</a></li><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/" target="_blank" rel="noopener">Installing kubeadm</a></li><li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/" target="_blank" rel="noopener">Creating a cluster with kubeadm</a></li><li><a href="https://github.com/cloudnativelabs/kube-router/blob/master/docs/kubeadm.md" target="_blank" rel="noopener">Deploying kube-router with kubeadm</a></li><li><a href="https://docs.projectcalico.org/getting-started/kubernetes/flannel/flannel" target="_blank" rel="noopener">Install Calico for policy and flannel (aka Canal) for networking</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 &lt;strong&gt;Ubuntu 20.04&lt;/strong&gt; 系统上搭建 &lt;strong&gt;Kubernetes&lt;/strong&gt; 集群。&lt;/p&gt;
&lt;h2 id=&quot;安装-Docker&quot;&gt;&lt;a href=&quot;#安装-Docker&quot; class=&quot;headerlink&quot; titl</summary>
      
    
    
    
    
    <category term="kubernetes" scheme="http://divinerapier.github.io/tags/kubernetes/"/>
    
    <category term="kubeadm" scheme="http://divinerapier.github.io/tags/kubeadm/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 20.04 配置静态网络</title>
    <link href="http://divinerapier.github.io/2020/10/19/configure-networks-on-ubuntu-20-04/"/>
    <id>http://divinerapier.github.io/2020/10/19/configure-networks-on-ubuntu-20-04/</id>
    <published>2020-10-19T10:55:44.000Z</published>
    <updated>2020-10-19T11:56:03.548Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Ubuntu 20.04</strong> 的网络配置文件位于 <strong>/etc/netplan/00-installer-config.yaml</strong>:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This is the network config written by 'subiquity'</span></span><br><span class="line"><span class="attr">network:</span></span><br><span class="line">  <span class="attr">ethernets:</span></span><br><span class="line">    <span class="attr">ens33:</span></span><br><span class="line">      <span class="attr">dhcp4:</span> <span class="literal">false</span></span><br><span class="line">      <span class="attr">addresses:</span> <span class="string">[192.168.50.30/24]</span></span><br><span class="line">      <span class="attr">gateway4:</span> <span class="number">192.168</span><span class="number">.50</span><span class="number">.1</span></span><br><span class="line">      <span class="attr">nameservers:</span></span><br><span class="line">        <span class="attr">addresses:</span> <span class="string">[192.168.50.1,</span> <span class="number">8.8</span><span class="number">.8</span><span class="number">.8</span><span class="string">]</span></span><br></pre></td></tr></table></figure><p>更新配置:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu-00:~<span class="comment"># netplan --debug apply</span></span><br><span class="line">** (generate:3768): DEBUG: 11:49:11.734: Processing input file /etc/netplan/00-installer-config.yaml..</span><br><span class="line">** (generate:3768): DEBUG: 11:49:11.734: starting new processing pass</span><br><span class="line">** (generate:3768): DEBUG: 11:49:11.735: We have some netdefs, pass them through a final round of validation</span><br><span class="line">** (generate:3768): DEBUG: 11:49:11.735: ens33: setting default backend to 1</span><br><span class="line">** (generate:3768): DEBUG: 11:49:11.735: Configuration is valid</span><br><span class="line">** (generate:3768): DEBUG: 11:49:11.736: Generating output files..</span><br><span class="line">** (generate:3768): DEBUG: 11:49:11.736: NetworkManager: definition ens33 is not <span class="keyword">for</span> us (backend 1)</span><br><span class="line">(generate:3768): GLib-DEBUG: 11:49:11.736: posix_spawn avoided (fd close requested)</span><br><span class="line">DEBUG:netplan generated networkd configuration changed, restarting networkd</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Ubuntu 20.04&lt;/strong&gt; 的网络配置文件位于 &lt;strong&gt;/etc/netplan/00-installer-config.yaml&lt;/strong&gt;:&lt;/p&gt;
&lt;figure class=&quot;highlight yaml&quot;&gt;&lt;table</summary>
      
    
    
    
    
    <category term="ubuntu" scheme="http://divinerapier.github.io/tags/ubuntu/"/>
    
    <category term="networks" scheme="http://divinerapier.github.io/tags/networks/"/>
    
  </entry>
  
  <entry>
    <title>Docker 中无法找到命令 configure</title>
    <link href="http://divinerapier.github.io/2020/10/18/command-configure-not-found-in-docker/"/>
    <id>http://divinerapier.github.io/2020/10/18/command-configure-not-found-in-docker/</id>
    <published>2020-10-18T13:02:27.000Z</published>
    <updated>2020-10-18T13:25:56.340Z</updated>
    
    <content type="html"><![CDATA[<p>通过进入基于 <code>ubuntu:20.04</code> 镜像运行的容器中安装 <strong>openmpi</strong> 的一系列指令得到了如下 <strong>dockerfile</strong> 片段:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> wget https://download.open-mpi.org/release/open-mpi/v4.0/openmpi-4.0.5.tar.gz</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> tar xzf openmpi-4.0.5.tar.gz -C /tmp</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">cd</span> /tmp/openmpi-4.0.5</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> ./configure --with-threads=posix --<span class="built_in">enable</span>-mpi-thread-multiple</span></span><br></pre></td></tr></table></figure><p>以上命令可以在容器中逐条执行，但却在构建镜像时失败:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/sh: 1: ./configure: not found</span><br></pre></td></tr></table></figure><p>提示 <strong>configure</strong> 不存在。</p><p>修复办法是将 <strong>configure</strong> 命令与前一条命令合并:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> wget https://download.open-mpi.org/release/open-mpi/v4.0/openmpi-4.0.5.tar.gz</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> tar xzf openmpi-4.0.5.tar.gz -C /tmp</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">cd</span> /tmp/openmpi-4.0.5 \</span></span><br><span class="line"><span class="bash">  &amp;&amp; ./configure --with-threads=posix --<span class="built_in">enable</span>-mpi-thread-multiple \</span></span><br><span class="line"><span class="bash">  &amp;&amp; make -j \</span></span><br><span class="line"><span class="bash">  &amp;&amp; make -j install</span></span><br></pre></td></tr></table></figure><p>推测原因: <strong>docker</strong> 镜像的每一层基于不同的 <strong>workdir</strong>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;通过进入基于 &lt;code&gt;ubuntu:20.04&lt;/code&gt; 镜像运行的容器中安装 &lt;strong&gt;openmpi&lt;/strong&gt; 的一系列指令得到了如下 &lt;strong&gt;dockerfile&lt;/strong&gt; 片段:&lt;/p&gt;
&lt;figure class=&quot;highl</summary>
      
    
    
    
    
    <category term="docker" scheme="http://divinerapier.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>GPU 101 - Architecture</title>
    <link href="http://divinerapier.github.io/2020/10/15/GPU-101-Architecture/"/>
    <id>http://divinerapier.github.io/2020/10/15/GPU-101-Architecture/</id>
    <published>2020-10-15T11:50:58.000Z</published>
    <updated>2020-10-15T12:42:54.195Z</updated>
    
    <content type="html"><![CDATA[<p><strong>图形处理器单元(GPU)</strong> 主要是指运行高度图形化应用时使用的硬件设备，比如 <strong>3D建模软件</strong> 或 <strong>VDI基础设施</strong>。在消费市场上，GPU多用于加速游戏图形。如今，GPGPU(General Purpose GPU) 是现代高性能计算 (HPC) 场景中加速计算的普遍硬件选择。</p><p>会用到 GPU 的领域除了我们熟悉的 HPC，比如会用到图像识别的机器学习方向，也常用在医疗、保险和金融行业相关的垂直领域中使用的 <a href="https://www.w3.org/TR/tabular-data-model/" target="_blank" rel="noopener">表格数据 (Tabular Data)</a> 的计算。</p><p>因此，就引出一个问题: 为什么需要使用 GPU 而不是 CPU?</p><h2 id="延迟与吞吐量"><a href="#延迟与吞吐量" class="headerlink" title="延迟与吞吐量"></a>延迟与吞吐量</h2><p>首先，来看看 CPU 和 GPU 的主要区别。</p><p>CPU 对速度与延迟方面进行了优化，在保持操作之间快速切换的能力的前提下，以尽可能低的延迟完成任务。它的本质就是以序列化的方式处理任务。</p><p>GPU 对吞吐量方面进行了优化，它允许一次推尽可能多的任务到内部，并通过并行方式处理每个任务。</p><p>下面的示例图显示了 CPU 和 GPU <strong>核心</strong> 的数量。显而易见地，GPU 具有更多的核心来处理一个任务。</p><p><img src="/images/GPU-101-Architecture/01-cpu-vs-gpu-cores.png" alt="cpu-vs-gpu-cores"></p><h2 id="异同点"><a href="#异同点" class="headerlink" title="异同点"></a>异同点</h2><p>然而，这不仅仅是核心数量的问题。而当我们说到NVIDIA GPU中的核心时，我们指的是由ALU（算术逻辑单元）组成的CUDA核心。不同厂商的术语可能会有所不同。</p><p>从CPU和GPU的整体架构来看，我们可以看到两者之间有很多相似之处。两者都使用了缓存层、内存控制器和全局内存的内存构造。对现代CPU架构的高层概述表明，它都是通过使用重要的缓存内存层来实现低延迟的内存访问。让我们先看一张图，它显示了一个通用的、以内存为中心的现代CPU封装（注意：精确的布局强烈地取决于供应商/型号）。</p><p><img src="/images/GPU-101-Architecture/02-cpu-hl-architecture.png" alt="cpu-hl-architecture"></p><p>一个CPU包由核心组成，包含独立的数据层和指令层-1缓存，由层-2缓存支持。第3层高速缓存，也就是最后一层高速缓存，由多个核心共享。如果数据没有驻留在缓存层中，它将从全局DDR-4内存中获取数据。每个CPU的核心数量可以达到28个或32个，根据品牌和型号的不同，在Turbo模式下可以运行到2.5GHz或3.8GHz。缓存大小范围为每个核心最高2MB二级缓存。</p><h2 id="探索GPU架构"><a href="#探索GPU架构" class="headerlink" title="探索GPU架构"></a>探索GPU架构</h2><p>如果我们检查GPU的高层架构概述（同样，强烈依赖make/model），看起来GPU的本质就是把可用的核心投入工作，它不太注重低延迟的缓存内存访问。</p><p><img src="/images/GPU-101-Architecture/03-gpu-architecture.png" alt="gpu-architecture"></p><p>单个GPU设备由多个处理器集群（PC）组成，其中包含多个流式多处理器（SM）。每个SM容纳一个第1层指令缓存层与其相关的核心。通常情况下，一个SM在从全局GDDR-5内存中提取数据之前，会使用一个专用的第1层缓存和一个共享的第2层缓存。其架构对内存延迟的容忍度很高。</p><p>与CPU相比，GPU工作的内存缓存层数较少，而且相对较小。原因是GPU有更多的晶体管用于计算，这意味着它不太在乎从内存中检索数据所需的时间。只要GPU手头有足够的计算量，潜在的内存访问 “延迟 “就会被掩盖，使其保持忙碌。</p><blockquote><p>A GPU is optimized for data parallel throughput computations.</p></blockquote><p>从核心数量来看，它很快就能让你看到它在并行方面的可能性。 当检查当前NVIDIA的旗舰产品Tesla V100时，一台设备包含80个SM，每个SM包含64个核心，总共有5120个核心！任务不是安排给单个核心，而是安排给处理器集群和SM。任务不是安排给单个核心，而是安排给处理器集群和SM。这就是它能够并行处理的原因。现在把这个强大的硬件设备和编程框架结合起来，应用就可以充分发挥GPU的计算能力。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul><li><a href="https://nielshagoort.com/2019/03/12/exploring-the-gpu-architecture/" target="_blank" rel="noopener">Exploring the GPU Architecture</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;图形处理器单元(GPU)&lt;/strong&gt; 主要是指运行高度图形化应用时使用的硬件设备，比如 &lt;strong&gt;3D建模软件&lt;/strong&gt; 或 &lt;strong&gt;VDI基础设施&lt;/strong&gt;。在消费市场上，GPU多用于加速游戏图形。如今，GPGPU(Ge</summary>
      
    
    
    
    
    <category term="gpu" scheme="http://divinerapier.github.io/tags/gpu/"/>
    
  </entry>
  
  <entry>
    <title>WSL2 中无法连接 Docker 服务</title>
    <link href="http://divinerapier.github.io/2020/10/15/cannot-connect-to-docker-daemon-on-wsl2/"/>
    <id>http://divinerapier.github.io/2020/10/15/cannot-connect-to-docker-daemon-on-wsl2/</id>
    <published>2020-10-15T09:21:20.000Z</published>
    <updated>2020-10-15T09:31:37.955Z</updated>
    
    <content type="html"><![CDATA[<p>在 <strong>WSL2</strong> 环境中使用 <strong>Docker</strong> 遇到错误:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker ps</span><br><span class="line">Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?</span><br></pre></td></tr></table></figure><p>可以通过如下操作解决:</p><ol><li><p>在 <strong>App and features</strong> 中卸载 <strong>Docker</strong> 程序</p></li><li><p>删除如下目录</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">C:\Program Files\Docker</span><br><span class="line">C:\ProgramData\DockerDesktop</span><br><span class="line">C:\Users\[USERNAME]\.docker</span><br><span class="line">C:\Users\[USERNAME]\AppData\Local\Docker</span><br><span class="line">C:\Users\[USERNAME]\AppData\Roaming\Docker</span><br><span class="line">C:\Users\[USERNAME]\AppData\Roaming\Docker Desktop</span><br></pre></td></tr></table></figure></li><li><p>下载最 <a href="https://docs.docker.com/docker-for-windows/edge-release-notes/" target="_blank" rel="noopener">新版本 <strong>Docker</strong></a></p></li><li><p>启动 <strong>Docker</strong></p></li></ol><p>到此为止，问题应该已经被解决了(至少我解决了)。</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://codesthq.com/painless-way-to-wsl-2-with-docker/" target="_blank" rel="noopener">Painless way to WSL 2 with Docker</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在 &lt;strong&gt;WSL2&lt;/strong&gt; 环境中使用 &lt;strong&gt;Docker&lt;/strong&gt; 遇到错误:&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span c</summary>
      
    
    
    
    
    <category term="windows" scheme="http://divinerapier.github.io/tags/windows/"/>
    
    <category term="wsl2" scheme="http://divinerapier.github.io/tags/wsl2/"/>
    
    <category term="docker" scheme="http://divinerapier.github.io/tags/docker/"/>
    
  </entry>
  
</feed>
